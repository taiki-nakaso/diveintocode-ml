{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sprint\n",
    "## 深層学習スクラッチ 畳み込みニューラルネットワーク2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.このSprintについて\n",
    "\n",
    "### Sprintの目的\n",
    "スクラッチを通してCNNの基礎を理解する\n",
    "\n",
    "### どのように学ぶか\n",
    "スクラッチで2次元用畳み込みニューラルネットワークを実装した後、学習と検証を行なっていきます"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2次元の畳み込みニューラルネットワークスクラッチ\n",
    "\n",
    "2次元に対応した畳み込みニューラルネットワーク（CNN）のクラスをスクラッチで作成していきます。NumPyなど最低限のライブラリのみを使いアルゴリズムを実装していきます。\n",
    "\n",
    "\n",
    "プーリング層なども作成することで、CNNの基本形を完成させます。クラスの名前はScratch2dCNNClassifierとしてください。\n",
    "\n",
    "\n",
    "### データセットの用意\n",
    "引き続きMNISTデータセットを使用します。2次元畳み込み層へは、28×28の状態で入力します。\n",
    "\n",
    "\n",
    "今回は白黒画像ですからチャンネルは1つしかありませんが、チャンネル方向の軸は用意しておく必要があります。\n",
    "\n",
    "\n",
    "`(n_samples, n_channels, height, width)`の`NCHW`または`(n_samples, height, width, n_channels)`の`NHWC`どちらかの形にしてください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-> `NCHW`のほうがよさそう？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "Using TensorFlow backend.\n"
    }
   ],
   "source": [
    "# import modules\n",
    "from keras.datasets import mnist\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題1】\n",
    "#### 2次元畳み込み層の作成\n",
    "1次元畳み込み層のクラスConv1dを発展させ、2次元畳み込み層のクラスConv2dを作成してください。\n",
    "\n",
    "\n",
    "フォワードプロパゲーションの数式は以下のようになります。\n",
    "\n",
    "$$\n",
    "a_{i,j,m} = \\sum_{k=0}^{K-1}\\sum_{s=0}^{F_{h}-1}\\sum_{t=0}^{F_{w}-1}x_{(i+s),(j+t),k}w_{s,t,k,m}+b_{m}\n",
    "$$\n",
    "\n",
    "$a_{i,j,m}$ : 出力される配列のi行j列、mチャンネルの値\n",
    "\n",
    "\n",
    "$i$ : 配列の行方向のインデックス\n",
    "\n",
    "\n",
    "$j$ : 配列の列方向のインデックス\n",
    "\n",
    "\n",
    "$m$ : 出力チャンネルのインデックス\n",
    "\n",
    "\n",
    "$K$ : 入力チャンネル数\n",
    "\n",
    "\n",
    "$F_h, F_w$ : 高さ方向（h）と幅方向（w）のフィルタのサイズ\n",
    "\n",
    "\n",
    "$x_{(i+s),(j+t),k}$ : 入力の配列の(i+s)行(j+t)列、kチャンネルの値\n",
    "\n",
    "\n",
    "$w_{s,t,k,m}$ : 重みの配列のs行t列目。kチャンネルの入力に対して、mチャンネルへ出力する重み\n",
    "\n",
    "\n",
    "$b_m$ : mチャンネルへの出力のバイアス項\n",
    "\n",
    "\n",
    "全てスカラーです。\n",
    "\n",
    "\n",
    "次に更新式です。1次元畳み込み層や全結合層と同じ形です。\n",
    "\n",
    "$$\n",
    "w_{s,t,k,m}^{\\prime} = w_{s,t,k,m} - \\alpha \\frac{\\partial L}{\\partial w_{s,t,k,m}} \\\\\n",
    "b_{m}^{\\prime} = b_{m} - \\alpha \\frac{\\partial L}{\\partial b_{m}}\n",
    "$$\n",
    "\n",
    "$\\alpha$ : 学習率\n",
    "\n",
    "\n",
    "$\\frac{\\partial L}{\\partial w_{s,t,k,m}}$ : $w_{s,t,k,m}$に関する損失$L$の勾配\n",
    "\n",
    "\n",
    "$\\frac{\\partial L}{\\partial b_{m}}$ : $b_m$に関する損失$L$の勾配\n",
    "\n",
    "\n",
    "勾配$\\frac{\\partial L}{\\partial w_{s,t,k,m}}$や$\\frac{\\partial L}{\\partial b_{m}}$を求めるためのバックプロパゲーションの数式が以下である。\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial w_{s,t,k,m}} = \\sum_{i=0}^{N_{out,h}-1}\\sum_{j=0}^{N_{out,w}-1} \\frac{\\partial L}{\\partial a_{i,j,m}}x_{(i+s),(j+t),k}\\\\\n",
    "\\frac{\\partial L}{\\partial b_{m}} = \\sum_{i=0}^{N_{out,h}-1}\\sum_{j=0}^{N_{out,w}-1}\\frac{\\partial L}{\\partial a_{i,j,m}}\n",
    "$$\n",
    "\n",
    "$\\frac{\\partial L}{\\partial a_{i,j,m}}$ : 勾配の配列のi行j列、mチャンネルの値\n",
    "\n",
    "\n",
    "$N_{out,h}, N_{out,w}$ : 高さ方向（h）と幅方向（w）の出力のサイズ\n",
    "\n",
    "\n",
    "前の層に流す誤差の数式は以下です。\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial x_{i,j,k}} = \\sum_{m=0}^{M-1}\\sum_{s=0}^{F_{h}-1}\\sum_{t=0}^{F_{w}-1} \\frac{\\partial L}{\\partial a_{(i-s),(j-t),m}}w_{s,t,k,m}\n",
    "$$\n",
    "\n",
    "\n",
    "$\\frac{\\partial L}{\\partial x_{i,j,k}}$ : 前の層に流す誤差の配列のi列j行、kチャンネルの値\n",
    "\n",
    "\n",
    "$M$ : 出力チャンネル数\n",
    "\n",
    "\n",
    "ただし、$i−s<0$または$i−s>N_{out,h}−1$または$j−t<0$または$j−t>N_{out,w}−1$のとき$\\frac{\\partial L}{\\partial a_{(i-s),(j-t),m}}=0$です。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題2】\n",
    "#### 2次元畳み込み後の出力サイズ\n",
    "畳み込みを行うと特徴マップのサイズが変化します。どのように変化するかは以下の数式から求められます。この計算を行う関数を作成してください。\n",
    "\n",
    "$$\n",
    "N_{h,out} =  \\frac{N_{h,in}+2P_{h}-F_{h}}{S_{h}} + 1\\\\\n",
    "N_{w,out} =  \\frac{N_{w,in}+2P_{w}-F_{w}}{S_{w}} + 1\n",
    "$$\n",
    "\n",
    "$N_{out}$ : 出力のサイズ（特徴量の数）\n",
    "\n",
    "\n",
    "$N_{in}$ : 入力のサイズ（特徴量の数）\n",
    "\n",
    "\n",
    "$P$ : ある方向へのパディングの数\n",
    "\n",
    "\n",
    "$F$ : フィルタのサイズ\n",
    "\n",
    "\n",
    "$S$ : ストライドのサイズ\n",
    "\n",
    "\n",
    "$h$が高さ方向、$w$が幅方向である"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2d:\n",
    "    \"\"\"\n",
    "\n",
    "    self.W (C_out, C_in, H, W)\n",
    "    self.B (C_out,)\n",
    "    \"\"\"\n",
    "    def __init__(self, output_ch, input_ch, filter_h, filter_w, lr, stride=1, pad=0):\n",
    "        self.output_ch = output_ch\n",
    "        self.input_ch = input_ch\n",
    "        self.filter_h = filter_h\n",
    "        self.filter_w = filter_w\n",
    "        self.lr = lr\n",
    "        self.stride = stride\n",
    "        self.pad = pad\n",
    "        self.W = np.random.randn(output_ch, input_ch, filter_h, filter_w)\n",
    "        self.B = np.random.randn(output_ch)\n",
    "\n",
    "    def forward(self, X):\n",
    "        # X (N, C_in, H, W)\n",
    "        self.X_ = X\n",
    "        N, C, H, W = X.shape\n",
    "        self.out_h, self.out_w = calc_out_size(H, W, self.filter_h, self.filter_w, stride=self.stride, pad=self.pad)\n",
    "\n",
    "        col = im2col(X, self.filter_h, self.filter_w, self.stride, self.pad)\n",
    "        col_W = self.W.reshape(self.output_ch, -1).T\n",
    "        # A (N*H*W, C_out)\n",
    "        A = np.dot(col, col_W) + self.B\n",
    "        # A (N, H, W, C_out) -> (N, C_out, H, W)\n",
    "        A = A.reshape(N, self.out_h, self.out_w, -1).transpose(0, 3, 1, 2)\n",
    "\n",
    "        return A\n",
    "\n",
    "    def backward(self, dA):\n",
    "            # dA (N, C_out, H, W)\n",
    "            \n",
    "            # dW (C_out, C_in, H, W)\n",
    "            dW = np.zeros(self.W.shape)\n",
    "            iterator_dW = itertools.product(range(self.filter_h),\n",
    "                                            range(self.filter_w),\n",
    "                                            range(self.input_ch),\n",
    "                                            range(self.output_ch))\n",
    "            for s, k, t, m in iterator_dW:\n",
    "                dW_tmp = 0\n",
    "                for i, j in itertools.product(range(self.out_h), range(self.out_w)):\n",
    "                    dW += np.mean(np.dot(dA[:, m, i, j], self.X_[:, k, i+s, j+t]), axis=0)\n",
    "                dW[m, k, s, t] = dW_tmp\n",
    "            \n",
    "            # dB (C_out,)\n",
    "            dB = np.zeros(self.B.shape)\n",
    "            for m in range(dB.shape[0]):\n",
    "                for i, j in itertools.product(range(self.out_h), range(self.out_w)):\n",
    "                    dB[m] = np.mean(np.sum(dA, axis=(2, 3)), axis=0)\n",
    "\n",
    "            # dX (N, C_in, H, W)\n",
    "            dX = np.zeros(self.X_.shape)\n",
    "            iterators_dX = itertools.product(range(self.output_ch),\n",
    "                                             range(self.filter_h),\n",
    "                                             range(self.filter_w))\n",
    "            for i, j, k in iterators_dX:\n",
    "                # 全バッチ分まとめて計算\n",
    "                dX_tmp = np.zeros(dX_tmp.shape[0])\n",
    "                for s, k, t, m in itertools.product(range(self.filter_h),\n",
    "                                                    range(self.filter_w),\n",
    "                                                    range(self.input_ch),\n",
    "                                                    range(self.output_ch)):\n",
    "                    if (i-s < 0) or (i-s > self.out_h-1) or (j-t < 0) or (j-t > self.out_w-1):\n",
    "                        continue\n",
    "                    else:\n",
    "                        dX_tmp += dA[:, m, (i-s), (j-t)] * self.W[m, k, s, t]\n",
    "                dX[:, k, i, j] = dX_tmp\n",
    "            \n",
    "            # update W/B\n",
    "            self.W = self.W - self.lr*dW\n",
    "            self.B = self.B - self.lr.dB\n",
    "\n",
    "            return dX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_out_size(input_h, input_w, filter_h, filter_w, stride, pad):\n",
    "    out_h = (input_h + 2*pad - filter_h)//stride + 1\n",
    "    out_w = (input_w + 2*pad - filter_w)//stride + 1\n",
    "    return (out_h, out_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def im2col(input_data, filter_h, filter_w, stride=1, pad=0):\n",
    "    N, C, H, W = input_data.shape\n",
    "    out_h, out_w = calc_out_size(H, W, filter_h, filter_w, stride, pad)\n",
    "\n",
    "    img = np.pad(input_data, [(0,0), (0,0), (pad, pad), (pad, pad)], 'constant')\n",
    "    col = np.zeros((N, C, filter_h, filter_w, out_h, out_w))\n",
    "\n",
    "    for y in range(filter_h):\n",
    "        y_max = y + stride*out_h\n",
    "        for x in range(filter_w):\n",
    "            x_max = x + stride*out_w\n",
    "            col[:, :, y, x, :, :] = img[:, :, y:y_max:stride, x:x_max:stride]\n",
    "\n",
    "    col = col.transpose(0, 4, 5, 1, 2, 3).reshape(N*out_h*out_w, -1)\n",
    "    return col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def col2im(col, input_shape, filter_h, filter_w, stride=1, pad=0):\n",
    "    N, C, H, W = input_shape\n",
    "    out_h, out_w = calc_out_size(H, W, filter_h, filter_w, stride, pad)\n",
    "    col = col.reshape(N, out_h, out_w, C, filter_h, filter_w).transpose(0, 3, 4, 5, 1, 2)\n",
    "\n",
    "    img = np.zeros((N, C, H + 2*pad + stride - 1, W + 2*pad + stride - 1))\n",
    "    for y in range(filter_h):\n",
    "        y_max = y + stride*out_h\n",
    "        for x in range(filter_w):\n",
    "            x_max = x + stride*out_w\n",
    "            img[:, :, y:y_max:stride, x:x_max:stride] += col[:, :, y, x, :, :]\n",
    "\n",
    "    return img[:, :, pad:H + pad, pad:W + pad]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題3】\n",
    "#### 最大プーリング層の作成\n",
    "最大プーリング層のクラスMaxPool2Dを作成してください。プーリング層は数式で表さない方が分かりやすい部分もありますが、数式で表すとフォワードプロパゲーションは以下のようになります。\n",
    "\n",
    "$$\n",
    "a_{i,j,k} = \\max_{(p,q)\\in P_{i,j}}x_{p,q,k}\n",
    "$$\n",
    "\n",
    "$P_{i,j}$ : i行j列への出力する場合の入力配列のインデックスの集合。$S_h \\times S_w$の範囲内の行（p）と列（q）\n",
    "\n",
    "\n",
    "$S_h, S_w$ : 高さ方向（h）と幅方向（w）のストライドのサイズ\n",
    "\n",
    "\n",
    "$(p,q)\\in P_{i,j}$ : $P_{i,j}$に含まれる行（p）と列（q）のインデックス\n",
    "\n",
    "\n",
    "$a_{i,j,k}$ : 出力される配列のi行j列、kチャンネルの値\n",
    "\n",
    "\n",
    "$x_{p,q,k}$ : 入力の配列のp行q列、kチャンネルの値\n",
    "\n",
    "\n",
    "ある範囲の中でチャンネル方向の軸は残したまま最大値を計算することになります。\n",
    "\n",
    "\n",
    "バックプロパゲーションのためには、フォワードプロパゲーションのときの最大値のインデックス$(p, q)$を保持しておく必要があります。フォワード時に最大値を持っていた箇所にそのままの誤差を流し、そこ以外には0を入れるためです。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaxPool2D:\n",
    "    \n",
    "    def __init__(self, pool_h, pool_w, stride=1, pad=0):\n",
    "        self.pool_h = pool_h\n",
    "        self.pool_w = pool_w\n",
    "        self.stride = stride\n",
    "        self.pad = pad\n",
    "    \n",
    "    def forward(self, X):\n",
    "        ## C_in = C_out?\n",
    "        # X (N, C_in, H, W)\n",
    "        N, C, H, W = X.shape\n",
    "        self.input_shape = (N, C, H, W)\n",
    "        out_h, out_w = calc_out_size(H, W, self.pool_h, self.pool_w, stride=self.stride, pad=self.pad)\n",
    "        \n",
    "        col = im2col(X, self.pool_h, self.pool_w, self.stride, self.pad)\n",
    "        # col (-1, pool_h*pool_w)\n",
    "        col = col.reshape(-1, self.pool_h*self.pool_w)\n",
    "        \n",
    "        # index保存\n",
    "        self.max_index = np.argmax(col, axis=1)\n",
    "\n",
    "        out = np.max(col, axis=1)\n",
    "\n",
    "        # out (N, C_out, H, W)\n",
    "        out = out.reshape(N, out_h, out_w, C).transpose(0, 3, 1, 2)\n",
    "\n",
    "        return out\n",
    "    \n",
    "    def backward(self, dX):\n",
    "        # dX (N, C, H, W)\n",
    "        dX = dX.transpose(0, 2, 3, 1)\n",
    "\n",
    "        pool_size = self.pool_h * self.pool_w \n",
    "        \n",
    "        dmax = np.zeros((dX.size, pool_size))\n",
    "        # 最大値を取るindexに誤差を代入\n",
    "        dmax[np.arange(self.max_index.size), self.max_index.flatten()] = dX.flatten()\n",
    "        dmax = dmax.reshape(dX.shape + (pool_size,))\n",
    "        \n",
    "        dcol = dmax.reshape(dmax.shape[0]*dmax.shape[1]*dmax.shape[2], -1)\n",
    "        dX_reshaped = col2im(dcol, self.input_shape, self.pool_h, self.pool_w, self.stride, self.pad)\n",
    "        \n",
    "        return dX_reshaped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[[1 2 3]\n [4 3 2]\n [6 5 4]\n [3 4 5]\n [6 7 5]]\n[3 4 6 5 7]\n"
    }
   ],
   "source": [
    "a = np.array([[1,2,3],[4,3,2], [6,5,4], [3,4,5], [6,7,5]])\n",
    "print(a)\n",
    "print(a[range(a.shape[0]), np.argmax(a, axis=1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題4】\n",
    "#### （アドバンス課題）平均プーリングの作成\n",
    "平均プーリング層のクラスAveragePool2Dを作成してください。\n",
    "\n",
    "\n",
    "範囲内の最大値ではなく、平均値を出力とするプーリング層です。\n",
    "\n",
    "\n",
    "画像認識関係では最大プーリング層が一般的で、平均プーリングはあまり使われません。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AveragePool2D:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題5】\n",
    "#### 平滑化\n",
    "平滑化するためのFlattenクラスを作成してください。\n",
    "\n",
    "\n",
    "フォワードのときはチャンネル、高さ、幅の3次元を1次元にreshapeします。その値は記録しておき、バックワードのときに再びreshapeによって形を戻します。\n",
    "\n",
    "\n",
    "この平滑化のクラスを挟むことで出力前の全結合層に適した配列を作ることができます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten:\n",
    "    \"\"\"\n",
    "    (N, C_out, H, W)を(N, C_out*H*W)にする\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def forward(self, X):\n",
    "        self.input_shape = X.shape\n",
    "\n",
    "        out = X.reshape(self.input_shape[0], -1)\n",
    "\n",
    "        return out\n",
    "\n",
    "    def backward(self, dX):\n",
    "        dX_reshaped = dX.reshape(self.input_shape)\n",
    "\n",
    "        return dX_reshaped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[[[[ 1  2]\n   [ 3  4]]\n\n  [[ 5  6]\n   [ 7  8]]]\n\n\n [[[ 9 10]\n   [11 12]]\n\n  [[13 14]\n   [15 16]]]]\n[[ 1  2  3  4  5  6  7  8]\n [ 9 10 11 12 13 14 15 16]]\n[[[[ 1  2]\n   [ 3  4]]\n\n  [[ 5  6]\n   [ 7  8]]]\n\n\n [[[ 9 10]\n   [11 12]]\n\n  [[13 14]\n   [15 16]]]]\n"
    }
   ],
   "source": [
    "a = np.array([[[[1,2],[3,4]],[[5,6],[7,8]]],[[[9,10],[11,12]],[[13,14],[15,16]]]])\n",
    "b = a.reshape(a.shape[0], -1)\n",
    "print(a)\n",
    "print(b)\n",
    "print(b.reshape(a.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.検証"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題6】\n",
    "#### 学習と推定\n",
    "作成したConv2dを使用してMNISTを学習・推定し、Accuracyを計算してください。\n",
    "\n",
    "\n",
    "精度は低くともまずは動くことを目指してください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DNN実装を拝借する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FC:\n",
    "    \"\"\"\n",
    "    ノード数n_nodes1からn_nodes2への全結合層\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_nodes1 : int\n",
    "      前の層のノード数\n",
    "    n_nodes2 : int\n",
    "      後の層のノード数\n",
    "    initializer : 初期化方法のインスタンス\n",
    "    optimizer : 最適化手法のインスタンス\n",
    "\n",
    "    Attribute\n",
    "    --------\n",
    "    self.W : ndarray(n_nodes1, n_nodes2)\n",
    "      重み\n",
    "    self.B : ndarray(n_node2,)\n",
    "      バイアス\n",
    "    self.H : float\n",
    "      前イテレーションまでの勾配の二乗和\n",
    "    \"\"\"\n",
    "    def __init__(self, n_nodes1, n_nodes2, initializer, optimizer):\n",
    "        self.optimizer = optimizer\n",
    "        # 初期化\n",
    "        # initializerのメソッドを使い、self.Wとself.Bを初期化する\n",
    "        self.W = initializer.W(n_nodes1, n_nodes2)\n",
    "        self.B = initializer.B(n_nodes2)\n",
    "        self.HW = np.zeros(self.W.shape)\n",
    "        self.HB = np.zeros(self.B.shape)\n",
    "        pass\n",
    "\n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        フォワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            入力\n",
    "        Returns\n",
    "        ----------\n",
    "        A : 次の形のndarray, shape (batch_size, n_nodes2)\n",
    "            出力\n",
    "        \"\"\"\n",
    "        self.Z_prev = X\n",
    "\n",
    "        A = X@self.W + self.B\n",
    "\n",
    "        return A\n",
    "\n",
    "    def backward(self, dA):\n",
    "        \"\"\"\n",
    "        バックワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        dA : 次の形のndarray, shape (batch_size, n_nodes2)\n",
    "            後ろから流れてきた勾配\n",
    "        Returns\n",
    "        ----------\n",
    "        dZ : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            前に流す勾配\n",
    "        \"\"\"\n",
    "\n",
    "        # 更新\n",
    "        dZ = self.optimizer.update(self, dA)\n",
    "\n",
    "        return dZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Softmax:\n",
    "    \"\"\"\n",
    "    ソフトマックス関数\n",
    "\n",
    "    Attribute\n",
    "    ----------\n",
    "    self.loss\n",
    "        出力の交差エントロピー誤差\n",
    "    \"\"\"\n",
    "    def forward(self, A):\n",
    "        Z = np.exp(A) / np.sum(np.exp(A), axis=1).reshape(-1, 1)\n",
    "        \n",
    "        return Z\n",
    "\n",
    "    def backward(self, Z, Y):\n",
    "        dA = Z - Y\n",
    "        self.loss = self.calc_cross_entropy_loss(Y, Z)\n",
    "\n",
    "        return dA\n",
    "    \n",
    "    def calc_cross_entropy_loss(self, y_true, y_pred):\n",
    "        n_samples = y_true.shape[0]\n",
    "\n",
    "        cross_entropy_loss = (-1 * (np.sum(y_true*np.log(y_pred)))) / n_samples\n",
    " \n",
    "        return cross_entropy_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReLU:\n",
    "    \"\"\"\n",
    "    ReLU関数\n",
    "\n",
    "    Attribute\n",
    "    ----------\n",
    "    self.A\n",
    "        活性化関数の入力\n",
    "    \"\"\"\n",
    "    def forward(self, A):\n",
    "        self.A = A\n",
    "        Z = np.maximum(0, A)\n",
    "        \n",
    "        return Z\n",
    "\n",
    "    def backward(self, dZ):\n",
    "        dA = dZ * np.where(self.A > 0, 1, 0)\n",
    "\n",
    "        return dA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HeInitializer:\n",
    "    \"\"\"\n",
    "    Heの初期値\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_nodes1 : int\n",
    "      前の層のノード数\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    self.sigma\n",
    "      ガウス分布の標準偏差\n",
    "    \"\"\"\n",
    "    def __init__(self, n_nodes1):\n",
    "        self.sigma = np.sqrt(2/n_nodes1)\n",
    "    \n",
    "    def W(self, n_nodes1, n_nodes2):\n",
    "        \"\"\"\n",
    "        重みの初期化\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_nodes1 : int\n",
    "          前の層のノード数\n",
    "        n_nodes2 : int\n",
    "          後の層のノード数\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        W :\n",
    "          重み\n",
    "        \"\"\"\n",
    "        W = self.sigma * np.random.randn(n_nodes1, n_nodes2)\n",
    "        \n",
    "        return W\n",
    "    \n",
    "    def B(self, n_nodes2):\n",
    "        \"\"\"\n",
    "        バイアスの初期化\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_nodes2 : int\n",
    "          後の層のノード数\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        B :\n",
    "          バイアス\n",
    "        \"\"\"\n",
    "        B = np.zeros((n_nodes2,))\n",
    "\n",
    "        return B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaGrad:\n",
    "    \"\"\"\n",
    "    AdaGrad法\n",
    "    Parameters\n",
    "    ----------\n",
    "    lr : 学習率\n",
    "    \"\"\"\n",
    "    def __init__(self, lr):\n",
    "        self.lr = lr\n",
    "\n",
    "    def update(self, layer, dA):\n",
    "        \"\"\"\n",
    "        ある層の重みやバイアスの更新\n",
    "        Parameters\n",
    "        ----------\n",
    "        layer : 更新前の層のインスタンス\n",
    "        \"\"\"\n",
    "        # calc partial\n",
    "        dB = np.mean(dA, axis=0)\n",
    "        dW = (layer.Z_prev.T@dA) / dA.shape[0]\n",
    "        dZ = dA@layer.W.T\n",
    "\n",
    "        # update HB, HW\n",
    "        layer.HB = layer.HB + dB**2\n",
    "        layer.HW = layer.HW + dW**2\n",
    "\n",
    "        # update W and B\n",
    "        layer.B = layer.B - self.lr*(1/(np.sqrt(layer.HB+1e-7)))*dB\n",
    "        layer.W = layer.W - self.lr*(1/(np.sqrt(layer.HW+1e-7)))*dW\n",
    "\n",
    "        return dZ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一旦\n",
    "\n",
    "*input -> Conv -> ReLU -> Pooling -> Flatten (-> Affine -> ReLU)+ -> Affine -> Softmax*\n",
    "\n",
    "で試してみる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScratchConvolutionalNeuralNetworkClassifier:\n",
    "    \"\"\"\n",
    "    畳み込みニューラルネットワーク分類器\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    alpha : float\n",
    "    sigma : float\n",
    "    batch_size : int\n",
    "    epoch : int\n",
    "    verbose : bool\n",
    "    output_ch : int\n",
    "    filter_size : tuple(int, int)\n",
    "    pooling_size : tuple(int, int)\n",
    "    stride : int\n",
    "    pad : int\n",
    "    n_nodes : list[int...]\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    self.loss : list\n",
    "    self.val_loss : list\n",
    "    \"\"\"\n",
    "    def __init__(self, alpha=0.01, sigma=0.01, batch_size=20, epoch=1, verbose=True,\n",
    "                 output_ch=10, filter_size=(3, 3), pooling_size=(2, 2), stride=1, pad=0, \n",
    "                 n_nodes=[100, 10]):\n",
    "        self.alpha = alpha\n",
    "        self.sigma = sigma\n",
    "        self.batch_size = batch_size\n",
    "        self.epoch = epoch\n",
    "        self.verbose = verbose\n",
    "        self.output_ch = output_ch\n",
    "        self.filter_size = filter_size\n",
    "        self.stride = stride\n",
    "        self.pad = pad \n",
    "        self.pooling_size = pooling_size\n",
    "        self.n_nodes = n_nodes\n",
    "\n",
    "    def fit(self, X, y, X_val=None, y_val=None):\n",
    "        \"\"\"\n",
    "        ニューラルネットワーク分類器を学習する。\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X (N, C, H, W)\n",
    "        y (N,)\n",
    "        X_val (N, C, H, W)\n",
    "        y_val (N)\n",
    "        \"\"\"\n",
    "        # def optimizer\n",
    "        optimizer = AdaGrad(self.alpha)\n",
    "\n",
    "        # def layers\n",
    "        self.layers = []\n",
    "        self.input_ch = X.shape[1]\n",
    "        \n",
    "        # first layer (Conv2d)\n",
    "        self.layers.append(Conv2d(self.output_ch,\n",
    "                                  self.input_ch,\n",
    "                                  *self.filter_size,\n",
    "                                  self.alpha,\n",
    "                                  stride=self.stride,\n",
    "                                  pad=self.pad))\n",
    "        # activator (ReLU)\n",
    "        self.layers.append(ReLU())\n",
    "\n",
    "        # pooling (MaxPool2D)\n",
    "        self.layers.append(MaxPool2D(*self.pooling_size, stride=self.stride, pad=self.pad))\n",
    "\n",
    "        # flatten (Flatten)\n",
    "        self.layers.append(Flatten())\n",
    "\n",
    "        # calc output size\n",
    "        self.output_size = calc_out_size(*calc_out_size(X.shape[2],\n",
    "                                                        X.shape[3],\n",
    "                                                        *self.filter_size,\n",
    "                                                        self.stride,\n",
    "                                                        self.pad),\n",
    "                                         *self.pooling_size,\n",
    "                                         self.stride,\n",
    "                                         self.pad)\n",
    "        self.output_size_flatten = self.output_ch*self.output_size[0]*self.output_size[1]\n",
    "\n",
    "        for i, (n_nodes1, n_nodes2) in enumerate(zip([self.output_size_flatten]+self.n_nodes[:-1], self.n_nodes)):\n",
    "            if i+1 != len(self.n_nodes):\n",
    "                # def initializer\n",
    "                initializer = HeInitializer(n_nodes1)\n",
    "\n",
    "                # def layer\n",
    "                self.layers.append(FC(n_nodes1, n_nodes2, initializer, optimizer))\n",
    "\n",
    "                # def activator\n",
    "                self.layers.append(ReLU())\n",
    "            # last layer\n",
    "            else:\n",
    "                # def initializer\n",
    "                initializer = HeInitializer(n_nodes1)\n",
    "\n",
    "                # def layer\n",
    "                self.layers.append(FC(n_nodes1, n_nodes2, initializer, optimizer))\n",
    "\n",
    "                # def activator\n",
    "                self.layers.append(Softmax())\n",
    "    \n",
    "        ## one-hot encoding\n",
    "        enc = OneHotEncoder(handle_unknown='ignore', sparse=False).fit(y[:, np.newaxis])\n",
    "        if y_val is not None:\n",
    "            y_val_one_hot = enc.transform(y_val[:, np.newaxis])\n",
    "\n",
    "        ## loss list\n",
    "        self.loss = []\n",
    "        self.val_loss = []\n",
    "\n",
    "        if self.verbose:\n",
    "            #verboseをTrueにした際は学習過程などを出力する\n",
    "            print('start learning')\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        # learning\n",
    "        for e in range(self.epoch):\n",
    "            print(f'start epoch {e+1}')\n",
    "\n",
    "            ## mini_batch\n",
    "            get_mini_batch = GetMiniBatch(X, y, batch_size=self.batch_size, seed=e)\n",
    "\n",
    "            ## loss list\n",
    "            self.loss.append([])\n",
    "\n",
    "            for i, (mini_X_train, mini_y_train) in enumerate(get_mini_batch):\n",
    "                ## one-hot encoding\n",
    "                mini_y_train_one_hot = enc.transform(mini_y_train[:, np.newaxis])\n",
    "                \n",
    "                # save output\n",
    "                output = None\n",
    "                for layer in self.layers:\n",
    "                    # forward\n",
    "                    if output is None:\n",
    "                        output = layer.forward(mini_X_train)\n",
    "                    else:\n",
    "                        output = layer.forward(output)\n",
    "                    \n",
    "                ## update weight, bias\n",
    "                ## append loss\n",
    "                dLoss = None\n",
    "                for layer in self.layers[::-1]:\n",
    "                    # backward\n",
    "                    if dLoss is None:\n",
    "                        dLoss = layer.backward(output, mini_y_train_one_hot)\n",
    "                        ## append loss \n",
    "                        self.loss[e].append(layer.loss)\n",
    "                    else:\n",
    "                        dLoss = layer.backward(dLoss)\n",
    "\n",
    "                ## print progress\n",
    "                if self.verbose:\n",
    "                    print(f'\\r{i+1}/{len(get_mini_batch)} loop finished', end='')\n",
    "\n",
    "            ## validation\n",
    "            if (X_val is not None) and (y_val is not None):\n",
    "                ### prediction\n",
    "                output_val = None\n",
    "                for layer in self.layers:\n",
    "                    # forward\n",
    "                    if output_val is None:\n",
    "                        output_val = layer.forward(X_val)\n",
    "                    else:\n",
    "                        output_val = layer.forward(output_val)\n",
    "\n",
    "                ### append loss\n",
    "                self.val_loss.append(self.layers[-1].calc_cross_entropy_loss(y_val_one_hot, output_val))\n",
    "\n",
    "            if self.verbose:\n",
    "                print(' : Complete!!')\n",
    "            if y_val is not None:\n",
    "                print(f'epoch {e+1} valid loss: {self.val_loss[-1]}')\n",
    "\n",
    "        end_time = time.time()\n",
    "        elapsed_time = end_time - start_time\n",
    "\n",
    "        # output loss\n",
    "        print(f'last train loss: {self.loss[-1][-1]}')\n",
    "\n",
    "        print(f'Done! elapsed time: {elapsed_time:.5f}s')\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        ニューラルネットワーク分類器を使い推定する。\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X (N, C, H, W)\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "            (n_samples, 1)\n",
    "        \"\"\"\n",
    "        # save output\n",
    "        output = None\n",
    "\n",
    "        ## forward propagation\n",
    "        for layer in self.layers:\n",
    "            if output is None:\n",
    "                output = layer.forward(X)\n",
    "            else:\n",
    "                output = layer.forward(output)\n",
    "\n",
    "        return np.argmax(output, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetMiniBatch:\n",
    "    \"\"\"\n",
    "    ミニバッチを取得するイテレータ\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : 次の形のndarray, shape (n_samples, n_features)\n",
    "      訓練データ\n",
    "    y : 次の形のndarray, shape (n_samples, 1)\n",
    "      正解値\n",
    "    batch_size : int\n",
    "      バッチサイズ\n",
    "    seed : int\n",
    "      NumPyの乱数のシード\n",
    "    \"\"\"\n",
    "    def __init__(self, X, y, batch_size = 20, seed=0):\n",
    "        self.batch_size = batch_size\n",
    "        np.random.seed(seed)\n",
    "        shuffle_index = np.random.permutation(np.arange(X.shape[0]))\n",
    "        self._X = X[shuffle_index]\n",
    "        self._y = y[shuffle_index]\n",
    "        self._stop = np.ceil(X.shape[0]/self.batch_size).astype(np.int)\n",
    "    def __len__(self):\n",
    "        return self._stop\n",
    "    def __getitem__(self,item):\n",
    "        p0 = item*self.batch_size\n",
    "        p1 = item*self.batch_size + self.batch_size\n",
    "        return self._X[p0:p1], self._y[p0:p1]        \n",
    "    def __iter__(self):\n",
    "        self._counter = 0\n",
    "        return self\n",
    "    def __next__(self):\n",
    "        if self._counter >= self._stop:\n",
    "            raise StopIteration()\n",
    "        p0 = self._counter*self.batch_size\n",
    "        p1 = self._counter*self.batch_size + self.batch_size\n",
    "        self._counter += 1\n",
    "        return self._X[p0:p1], self._y[p0:p1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "学習してみる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(48000, 1, 28, 28)\n(12000, 1, 28, 28)\n(10000, 1, 28, 28)\n"
    }
   ],
   "source": [
    "# データのロード\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "X_train = X_train[:, np.newaxis]\n",
    "X_test = X_test[:, np.newaxis]\n",
    "X_train = X_train.astype(np.float)\n",
    "X_test = X_test.astype(np.float)\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2)\n",
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "start learning\nstart epoch 1\n"
    },
    {
     "output_type": "error",
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-54-377a22969c21>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m }\n\u001b[0;32m      7\u001b[0m \u001b[0mscratchCNN\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mScratchConvolutionalNeuralNetworkClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mscratchCNN\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-35-a90ab752a33e>\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, X_val, y_val)\u001b[0m\n\u001b[0;32m    151\u001b[0m                         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m                     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 153\u001b[1;33m                         \u001b[0mdLoss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdLoss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    154\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m                 \u001b[1;31m## print progress\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-3b52cc451759>\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, dA)\u001b[0m\n\u001b[0;32m     43\u001b[0m                 \u001b[0mdW_tmp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mitertools\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mproduct\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mout_h\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mout_w\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m                     \u001b[0mdW\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdA\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mX_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m                 \u001b[0mdW\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdW_tmp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mmean\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dic\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36mmean\u001b[1;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[0;32m   3330\u001b[0m             \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3331\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3332\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3333\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3334\u001b[0m     return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dic\\lib\\site-packages\\numpy\\core\\_methods.py\u001b[0m in \u001b[0;36m_mean\u001b[1;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m     \u001b[0mis_float16_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 138\u001b[1;33m     \u001b[0mrcount\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_count_reduce_items\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    139\u001b[0m     \u001b[1;31m# Make this warning show up first\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mrcount\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dic\\lib\\site-packages\\numpy\\core\\_methods.py\u001b[0m in \u001b[0;36m_count_reduce_items\u001b[1;34m(arr, axis)\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[0mitems\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0max\u001b[0m \u001b[1;32min\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m         \u001b[0mitems\u001b[0m \u001b[1;33m*=\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     58\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mitems\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "# 学習\n",
    "# batch_size, epoch以外はデフォルトで確認\n",
    "params = {\n",
    "    'batch_size':200,\n",
    "    'epoch':5,\n",
    "}\n",
    "scratchCNN = ScratchConvolutionalNeuralNetworkClassifier(**params)\n",
    "scratchCNN.fit(X_train, y_train, X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'scratchDNN' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-50b5b0f4c381>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0my_test_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscratchDNN\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'Accuracy: {accuracy_score(y_test, y_test_pred)}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'scratchDNN' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "y_test_pred = scratchDNN.predict(X_test)\n",
    "print(y_test_pred)\n",
    "print(y_test)\n",
    "print(f'Accuracy: {accuracy_score(y_test, y_test_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'y_test_pred' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-80376a1631d0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mconf_m\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconf_m\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0msample_sum\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconf_m\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconf_m\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y_test_pred' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "conf_m = confusion_matrix(y_test, y_test_pred) \n",
    "print(conf_m)\n",
    "sample_sum = np.sum(conf_m, axis=1)\n",
    "for i in range(conf_m.shape[0]):\n",
    "    correct = conf_m[i][i]\n",
    "    incorrect = sample_sum[i] - correct\n",
    "    print(f'{i}: {correct}:{incorrect} {correct/sample_sum[i]:.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'plot_loss' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-9e331add651e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplot_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscratchDNN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'plot_loss' is not defined"
     ]
    }
   ],
   "source": [
    "plot_loss(scratchDNN)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}