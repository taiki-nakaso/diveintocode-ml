{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sprint\n",
    "## 機械学習フロー\n",
    "丁寧な検証が行える状態にした上で、他者の解法を参考に汎化性能の高いモデル作りを進めます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題1】\n",
    "## クロスバリデーション\n",
    "事前学習期間では検証データをはじめに分割しておき、それに対して指標値を計算することで検証を行っていました。（ホールドアウト法）しかし、分割の仕方により精度は変化します。実践的には クロスバリデーション（交差検証） を行います。分割を複数回行い、それぞれに対して学習と検証を行う方法です。複数回の分割のためにscikit-learnにはKFoldクラスが用意されています。\n",
    "\n",
    "事前学習期間の課題で作成したベースラインモデルに対してKFoldクラスによるクロスバリデーションを行うコードを作成し実行してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データセット読み込み\n",
    "credits_train = pd.read_csv('application_train.csv')\n",
    "credits_test = pd.read_csv('application_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = credits_train[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']].values\n",
    "y = credits_train['TARGET']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_and_fill(X, scaler):\n",
    "    # 標準化\n",
    "    X_norm = scaler.transform(X)\n",
    "\n",
    "    # 欠損値確認\n",
    "    nan_num = np.isnan(X_norm).sum()\n",
    "\n",
    "    # 穴埋め用乱数生成 - arr_replace\n",
    "    rands = np.random.normal(0, 1, nan_num)\n",
    "    arr_replace = np.zeros(X_norm.shape)\n",
    "    np.place(arr_replace, np.isnan(X_norm), rands)\n",
    "\n",
    "    # 欠損値穴埋め\n",
    "    X_norm_filled = np.where(np.isnan(X_norm), arr_replace, X_norm)\n",
    "    return X_norm_filled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "split: 5\n1. AUC - test: 0.6455288079408439\n2. AUC - test: 0.6517000510935217\n3. AUC - test: 0.6497391949973208\n4. AUC - test: 0.6522689109152051\n5. AUC - test: 0.6506231475455044\nAUC - test/average: 0.6499720224984792\n"
    }
   ],
   "source": [
    "# KFold検証\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "kf = KFold(n_splits=5)\n",
    "scaler = StandardScaler()\n",
    "rforest = RandomForestClassifier()\n",
    "print(f'split: {kf.get_n_splits(X)}')\n",
    "auc_arr = np.zeros(kf.get_n_splits(X))\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(kf.split(X)):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    # スケーリングとか\n",
    "    scaler.fit(X_train)\n",
    "    X_train_new = scale_and_fill(X_train, scaler)\n",
    "    # 学習・予測\n",
    "    rforest.fit(X_train_new, y_train)\n",
    "    # バリデーション\n",
    "    X_test_new = scale_and_fill(X_test, scaler)\n",
    "    y_test_pred = rforest.predict_proba(X_test_new)[:, 1]\n",
    "    auc_score = roc_auc_score(y_test, y_test_pred)\n",
    "    auc_arr[i] = auc_score\n",
    "    print(f'{i+1}. AUC - test: {auc_score}')\n",
    "\n",
    "print(f'AUC - test/average: {np.mean(auc_arr)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題2】\n",
    "## グリッドサーチ\n",
    "これまで分類器のパラメータには触れず、デフォルトの設定を使用していました。パラメータの詳細は今後のSprintで学んでいくことになります。機械学習の前提として、パラメータは状況に応じて最適なものを選ぶ必要があります。最適なパラメータを探していくことを パラメータチューニング と呼びます。パラメータチューニングをある程度自動化する単純な方法としては グリッドサーチ があります。\n",
    "\n",
    "scikit-learnのGridSearchCVを使い、グリッドサーチを行うコードを作成してください。そして、ベースラインモデルに対して何らかしらのパラメータチューニングを行なってください。どのパラメータをチューニングするかは、使用した手法の公式ドキュメントを参考にしてください。\n",
    "\n",
    "[sklearn.model_selection.GridSearchCV — scikit-learn 0.21.3 documentation](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)\n",
    "\n",
    "GridSearchCVクラスには引数としてモデル、探索範囲、さらにクロスバリデーションを何分割で行うかを与えます。クロスバリデーションの機能も含まれているため、これを使用する場合はKFoldクラスを利用する必要はありません。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最終チェック用\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X, y, stratify=y)\n",
    "\n",
    "scaler.fit(X2_train)\n",
    "X2_train_new = scale_and_fill(X2_train, scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n[Parallel(n_jobs=1)]: Done  72 out of  72 | elapsed: 47.9min finished\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "GridSearchCV(cv=3, error_score=nan,\n             estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n                                              class_weight=None,\n                                              criterion='gini', max_depth=None,\n                                              max_features='auto',\n                                              max_leaf_nodes=None,\n                                              max_samples=None,\n                                              min_impurity_decrease=0.0,\n                                              min_impurity_split=None,\n                                              min_samples_leaf=1,\n                                              min_samples_split=2,\n                                              min_weight_fraction_leaf=0.0,\n                                              n_estimators=100, n_jobs=None,\n                                              oob_score=False,\n                                              random_state=None, verbose=0,\n                                              warm_start=False),\n             iid='deprecated', n_jobs=None,\n             param_grid={'criterion': ['gini', 'entropy'],\n                         'min_samples_split': [1, 2, 5],\n                         'n_estimators': [10, 50, 100, 500]},\n             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n             scoring=None, verbose=1)"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "# グリッドサーチ\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "rforest2 = RandomForestClassifier()\n",
    "params = {\n",
    "    'n_estimators': [10, 50, 100, 500],\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'min_samples_split': [1, 2, 5]\n",
    "}\n",
    "gscv = GridSearchCV(rforest2, param_grid=params, cv=3, verbose=1)\n",
    "gscv.fit(X2_train_new, y2_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "best score: 0.9180602944355566\nbest params: {'criterion': 'gini', 'min_samples_split': 5, 'n_estimators': 500}\n"
    }
   ],
   "source": [
    "# 最適パラメータ確認\n",
    "print(f'best score: {gscv.best_score_}')\n",
    "print(f'best params: {gscv.best_params_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "AUC: 0.6680807596824182\nRandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n                       criterion='gini', max_depth=None, max_features='auto',\n                       max_leaf_nodes=None, max_samples=None,\n                       min_impurity_decrease=0.0, min_impurity_split=None,\n                       min_samples_leaf=1, min_samples_split=5,\n                       min_weight_fraction_leaf=0.0, n_estimators=500,\n                       n_jobs=None, oob_score=False, random_state=None,\n                       verbose=0, warm_start=False)\n"
    }
   ],
   "source": [
    "# 最適パラメータでバリデーションを行う\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "X2_test_new = scale_and_fill(X2_test, scaler)\n",
    "best = gscv.best_estimator_\n",
    "y2_test_pred = best.predict_proba(X2_test_new)[:, 1]\n",
    "\n",
    "print(f'AUC: {roc_auc_score(y2_test, y2_test_pred)}')\n",
    "print(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testデータに対する推測を行う\n",
    "def out_pred_csv(df, X, model, filename='out_pred.csv'):\n",
    "    \"\"\"\n",
    "    信用情報分析コンペ向けcsv排出関数\n",
    "    df: ID取得用DataFrame\n",
    "    X: 処理済み特徴量（ID含まない） ndarray\n",
    "    model: 予測モデル\n",
    "    \"\"\"\n",
    "    ids = df['SK_ID_CURR'].values\n",
    "    y_pred = model.predict_proba(X)[:, 1]\n",
    "    submit_arr = np.concatenate((ids.reshape(-1, 1), y_pred.reshape(-1, 1)), axis=1)\n",
    "    submit_df = pd.DataFrame(submit_arr, columns=['SK_ID_CURR', 'TARGET'])\n",
    "    submit_df['SK_ID_CURR'] = submit_df['SK_ID_CURR'].astype(np.int32)\n",
    "    display(submit_df)\n",
    "    submit_df.info()\n",
    "    submit_df.to_csv(filename, index=False)\n",
    "\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_submit = scale_and_fill(credits_test[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']].values, scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "       SK_ID_CURR    TARGET\n0          100001  0.016143\n1          100005  0.121458\n2          100013  0.004667\n3          100028  0.044424\n4          100038  0.132554\n...           ...       ...\n48739      456221  0.054848\n48740      456222  0.019690\n48741      456223  0.029643\n48742      456224  0.024417\n48743      456250  0.101616\n\n[48744 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>SK_ID_CURR</th>\n      <th>TARGET</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>100001</td>\n      <td>0.016143</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>100005</td>\n      <td>0.121458</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>100013</td>\n      <td>0.004667</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>100028</td>\n      <td>0.044424</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>100038</td>\n      <td>0.132554</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>48739</th>\n      <td>456221</td>\n      <td>0.054848</td>\n    </tr>\n    <tr>\n      <th>48740</th>\n      <td>456222</td>\n      <td>0.019690</td>\n    </tr>\n    <tr>\n      <th>48741</th>\n      <td>456223</td>\n      <td>0.029643</td>\n    </tr>\n    <tr>\n      <th>48742</th>\n      <td>456224</td>\n      <td>0.024417</td>\n    </tr>\n    <tr>\n      <th>48743</th>\n      <td>456250</td>\n      <td>0.101616</td>\n    </tr>\n  </tbody>\n</table>\n<p>48744 rows × 2 columns</p>\n</div>"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 48744 entries, 0 to 48743\nData columns (total 2 columns):\n #   Column      Non-Null Count  Dtype  \n---  ------      --------------  -----  \n 0   SK_ID_CURR  48744 non-null  int32  \n 1   TARGET      48744 non-null  float64\ndtypes: float64(1), int32(1)\nmemory usage: 571.3 KB\nTrue\n"
    }
   ],
   "source": [
    "print(out_pred_csv(credits_test, X_test_submit, best, filename='sprint1-2.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題3】\n",
    "## Kaggle Notebooksからの調査\n",
    "KaggleのNotebooksから様々なアイデアを見つけ出して、列挙してください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題4】\n",
    "## 高い汎化性能のモデル作成\n",
    "問題3で見つけたアイデアと、独自のアイデアを組み合わせ高い汎化性能のモデル作りを進めてください。\n",
    "\n",
    "その過程として、何を行うことで、クロスバリデーションの結果がどの程度変化したかを表にまとめてください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題5】\n",
    "## 最終的なモデルの選定\n",
    "最終的にこれは良いというモデルを選び、推定した結果をKaggleに提出してスコアを確認してください。どういったアイデアを取り入れ、どの程度のスコアになったかを記載してください。"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}