{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sprint\n",
    "## 機械学習スクラッチ クラスタリング\n",
    "スクラッチでK-meansを実装した後、それを使用しクラスタ分析を行います。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-meansのクラスをスクラッチで作成していきます。NumPyなど最低限のライブラリのみを使いアルゴリズムを実装していきます。\n",
    "\n",
    "\n",
    "以下に雛形を用意してあります。このScratchKMeansクラスにコードを書き加えていってください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "class ScratchKMeans():\n",
    "    \"\"\"\n",
    "    K-meansのスクラッチ実装\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_clusters : int\n",
    "      クラスタ数\n",
    "    n_init : int\n",
    "      中心点の初期値を何回変えて計算するか\n",
    "    max_iter : int\n",
    "      1回の計算で最大何イテレーションするか\n",
    "    tol : float\n",
    "      イテレーションを終了する基準となる中心点と重心の許容誤差\n",
    "    verbose : bool\n",
    "      学習過程を出力する場合はTrue\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    self.mu : ndarray(n_clusters, n_features)\n",
    "      クラスタの中心点\n",
    "    self.r_binary : ndarray(n_samples, n_clusters)\n",
    "      サンプル毎の所属クラスタをone-hot表現で表した配列\n",
    "    \"\"\"\n",
    "    def __init__(self, n_clusters, n_init, max_iter, tol, verbose=False):\n",
    "        # ハイパーパラメータを属性として記録\n",
    "        self.n_clusters = n_clusters\n",
    "        self.n_init = n_init\n",
    "        self.max_iter = max_iter\n",
    "        self.tol = tol\n",
    "        self.verbose = verbose\n",
    "    \n",
    "    def fit(self, X):\n",
    "        \"\"\"\n",
    "        K-meansによるクラスタリングを計算\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            訓練データの特徴量\n",
    "        \"\"\"\n",
    "        # preparing\n",
    "        n_samples = X.shape[0]\n",
    "        self.mu = X[np.random.choice(n_samples, self.n_clusters, replace=False), :]\n",
    "        self.r_binary = None\n",
    "\n",
    "        if self.verbose:\n",
    "            #verboseをTrueにした際は学習過程を出力\n",
    "            print('start learning')\n",
    "        pass\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        入力されたデータがどのクラスタに属するかを計算\n",
    "        \"\"\"\n",
    "        pass\n",
    "        return\n",
    "\n",
    "    def _each_diff_norm_squared(self, A, B):\n",
    "        \"\"\"\n",
    "        行列A,Bから一行ずつ選び出し、その差のベクトルのノルムの二乗||(A_i)-(B_j)||^2を計算する\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        A, B : ndarray\n",
    "            行列 1行が一つのベクトルに対応している\n",
    "        Return\n",
    "        ----------\n",
    "          ndarray(A.shape[0], B.shape(0))\n",
    "        \"\"\"\n",
    "        A_norm = np.linalg.norm(A, axis=1)\n",
    "\n",
    "        B_norm = np.linalg.norm(B, axis=1)\n",
    "\n",
    "        A_dot_B = A@B.T\n",
    "\n",
    "        norm_squared = A_norm_tile.reshape(-1, 1)**2 + B_norm_tile**2 - A_dot_B\n",
    "\n",
    "        return norm_squared\n",
    "\n",
    "    def _calc_SSE(self, X):\n",
    "        \"\"\" \n",
    "        クラスタ内誤差平方和を計算する。\n",
    "\n",
    "        \"\"\"\n",
    "        # calc sse\n",
    "        _sse = np.sum(self.r_binary * self._each_diff_norm_squared(X, self.mu))\n",
    "\n",
    "        return _sse\n",
    "\n",
    "    def _assign_cluster(self, X):\n",
    "        \"\"\"\n",
    "        データ点をもっとも近い中心点が属するクラスタに割り当てる\n",
    "        \"\"\"\n",
    "        # calc norm\n",
    "        _each_diff_norm = np.sqrt(self._each_diff_norm_squared(X, self.mu))\n",
    "\n",
    "        # one-hot\n",
    "        _r_binary = np.zeros((X.shape[0], self.n_clusters))\n",
    "        _r_binary[range(_r_binary.shape[0]), np.argmin(_each_diff_norm, axis=1)] = 1\n",
    "\n",
    "        return _r_binary\n",
    "\n",
    "    def _move_mu(self, X):\n",
    "        \"\"\"\n",
    "        クラスタの中心点の位置をクラスタの重心まで移動する\n",
    "        \"\"\"\n",
    "        mu_new = np.concatenate([np.nanmean() for i in range(self.n_clusters)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[0 1 2]\n[[1 2]\n [3 4]\n [5 6]]\n[3. 4.]\n"
    }
   ],
   "source": [
    "a = np.array([1,1,1,0]).reshape(-1,1)\n",
    "b = np.array([[1,2], [3,4], [5,6], [7,8]])\n",
    "c = np.unique(np.nonzero(a*b)[0])\n",
    "print(c)\n",
    "print(b[c])\n",
    "print(np.mean(b[c], axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## クラスタリングのための人工データセット\n",
    "クラスタリングを実験するための人工データセットを作成するコードを用意しています。\n",
    "\n",
    "\n",
    "この`make_blobs`関数は正解ラベルも出力してますが、今回は使用しません。使用しないことを明示するために、 \\_（アンダースコア） で受け取っています。\n",
    "\n",
    "\n",
    "**《シンプルデータセット3》**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[[ 0.72086751  3.71347124]\n [-1.89468423  7.96898545]\n [ 1.35678894  4.36462484]\n [ 1.05374379  4.49286859]\n [ 1.59141542  4.90497725]\n [ 0.78260667  4.15263595]\n [-1.95751686  3.87291474]\n [-0.77354537  7.87923564]\n [ 0.12313498  5.27917503]\n [-1.43284669  7.71577043]\n [-0.92819001  7.02698199]\n [-1.74836345  7.06307447]\n [-1.26789718  7.25141327]\n [-0.98661744  7.74968685]\n [-0.81984047  7.50994722]\n [ 2.99684287  0.22378413]\n [ 1.46870582  1.86947425]\n [-0.33533163  3.390122  ]\n [-1.86407034  2.93379754]\n [ 2.62496786  0.28025075]\n [ 2.11114739  3.57660449]\n [-1.8219901   7.61654999]\n [-1.91186205  3.18750686]\n [ 2.28809874  0.12954182]\n [ 0.5285368   4.49723858]\n [-1.57613028  2.58614312]\n [-0.565433    3.65813966]\n [ 0.802314    4.38196181]\n [ 2.79939362  1.84560825]\n [ 2.64465731  0.80770124]\n [ 1.7190373   0.71788708]\n [-0.93564005  7.03443119]\n [ 2.14398059  0.69677319]\n [ 2.06051753  1.79059891]\n [-1.21986433  3.3789856 ]\n [ 1.13280393  3.87673946]\n [-1.497272    8.80022604]\n [ 1.85367905  1.5088862 ]\n [-0.1666378   8.50372399]\n [-1.89928142  2.50466299]\n [ 1.04829186  5.03092408]\n [-1.44356727  3.23539798]\n [-1.57006498  6.72375844]\n [-1.98331513  3.47639041]\n [-1.87418794  2.84306499]\n [-1.86097353  8.2576415 ]\n [ 1.61986895  0.60823883]\n [-1.84482705  3.25609891]\n [ 0.72144399  4.08475018]\n [ 0.5323772   3.31338909]\n [ 0.3498724   4.69253251]\n [ 1.89949126  0.92574633]\n [-1.2386086   2.81373288]\n [-1.74448079  3.84251413]\n [-0.96358605  2.37791651]\n [-1.26041884  7.46644456]\n [-0.8623605   8.24721209]\n [ 2.4198128   0.96215512]\n [ 2.23345072  1.25095024]\n [-0.65424088  7.99393132]\n [-1.42525273  7.14798437]\n [ 1.51989121  1.42488952]\n [ 2.11872357  1.09865834]\n [ 1.74265969  5.03846671]\n [ 1.42002502  1.38236201]\n [-0.69842598  8.16309188]\n [-2.18485772  2.68708996]\n [-1.32890066  2.37135151]\n [ 2.15940501  1.38598318]\n [ 1.19820169  4.47062449]\n [-1.7653772   8.17625727]\n [ 1.4726926   1.3480769 ]\n [ 0.92466065  4.50908658]\n [-1.47602203  7.8441996 ]\n [ 0.99914934  4.2101954 ]\n [ 1.40848818  3.93270482]\n [-0.59312453  3.37090459]\n [-1.6609057   3.31911046]\n [ 2.25643834  0.55525861]\n [ 1.24016835  1.12905479]\n [ 1.64869438  0.03452236]\n [-1.61803727  8.60696731]\n [-1.37778493  3.58107521]\n [ 0.16932115  4.19741719]\n [ 1.73810647  0.71629308]\n [-1.05327803  2.84037721]\n [ 1.60161834  0.92363636]\n [ 1.84845803  0.52393625]\n [ 1.72330962  4.2012082 ]\n [ 1.00952869  4.45502328]\n [ 0.96217896  4.51795326]\n [-1.33869125  2.36818187]\n [ 0.4519936   3.59377836]\n [-1.19075663  3.12161318]\n [-2.27253281  3.13757811]\n [-1.80044744  7.86154256]\n [-1.64996061  7.49068513]\n [-1.56102482  3.77455362]\n [-0.78782636  7.99482384]\n [-0.30022483  4.63059663]]\n"
    }
   ],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "X, _ = make_blobs(n_samples=100, n_features=2, centers=4, cluster_std=0.5, shuffle=True, random_state=0)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題1】\n",
    "## 中心点の初期値を決める\n",
    "入力されたデータから$K$個の中心点$μ_1$から$μ_K$の初期値を決めるコードを作成してください。$K$は指定したクラスタ数です。\n",
    "\n",
    "\n",
    "最もシンプルな初期値の決定方法は、データ点$X_n$の中からランダムに$K$個選ぶことです。今回はこれを実装してください。\n",
    "\n",
    "\n",
    "K-meansの学習結果は中心点$μ$の初期値に影響を受けます。そのため、学習時には複数個の初期値で計算を行います。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "n_samples = X.shape[0]\n",
    "self.mu = X[np.random.randint(0, n_samples, self.n_clusters), :]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題2】\n",
    "## SSEを求める関数の作成\n",
    "クラスタ内誤差平方和（SSE, Sum of Squared Errors）を計算する関数を作成してください。\n",
    "\n",
    "\n",
    "K-meansはこのSSEを最小化する$r_{nk}$と$\\mu_k$を求めることが目的となります。複数個の初期値で計算したクラスタリング結果から、どれを最終的に採用するかを決める際にこのSSEを求める関数を使用します。\n",
    "\n",
    "$$\n",
    "SSE = \\sum_{n=1}^N \\sum_{k=1}^K r_{nk} \\|X_n - \\mu_k\\|^2\n",
    "$$\n",
    "\n",
    "$n$ : データ点のインデックス\n",
    "\n",
    "\n",
    "$k$ : クラスタのインデックス\n",
    "\n",
    "\n",
    "$X_n$ : $n$番目のデータ点\n",
    "\n",
    "\n",
    "$\\mu_k$ : $k$番目の中心点\n",
    "\n",
    "\n",
    "$r_{nk}$ : データ点$X_n$がクラスタ$k$に所属していたら1、そうでなければ0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下の式から計算する。\n",
    "$$\n",
    "\\|A-B\\|^2 = \\|A\\|^2 + \\|B\\|^2 - 2*(A \\cdot B)\n",
    "$$\n",
    "-> `_each_diff_norm_squared(A, B)`\n",
    "```python\n",
    "    def _each_diff_norm_squared(self, A, B):\n",
    "        \"\"\"\n",
    "        行列A,Bから一行ずつ選び出し、その差のベクトルのノルムの二乗||(A_i)-(B_j)||^2を計算する\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        A, B : ndarray\n",
    "            行列 1行が一つのベクトルに対応している\n",
    "        Return\n",
    "        ----------\n",
    "          ndarray(A.shape[0], B.shape(0))\n",
    "        \"\"\"\n",
    "        A_norm = np.linalg.norm(A, axis=1)\n",
    "\n",
    "        B_norm = np.linalg.norm(B, axis=1)\n",
    "\n",
    "        A_dot_B = A@B.T\n",
    "\n",
    "        norm_squared = A_norm_tile.reshape(-1, 1)**2 + B_norm_tile**2 - A_dot_B\n",
    "\n",
    "        return norm_squared\n",
    "\n",
    "    def _calc_SSE(self, X):\n",
    "        \"\"\" \n",
    "        クラスタ内誤差平方和を計算する。\n",
    "\n",
    "        \"\"\"\n",
    "        # calc sse\n",
    "        _sse = np.sum(self.r_binary * self._each_diff_norm_squared(X, self.mu))\n",
    "\n",
    "        return _sse\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## クラスタの割り当てと中心点の移動を繰り返す\n",
    "K-meansの学習の基本は以下の2つのフェーズを繰り返すことです。\n",
    "\n",
    "\n",
    "- 中心点$\\mu_k$を固定した上で$SSE$を最小化するクラスタの割り当て$r_{nk}$を選ぶ。\n",
    "- クラスタの割り当て$r_{nk}$を固定した上で$SSE$を最小化する中心点$\\mu_k$を選ぶ。\n",
    "\n",
    "最初の中心点$\\mu_k$は問題1で作成した初期値です。\n",
    "\n",
    "\n",
    "順番に見ていきます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題3】\n",
    "## クラスタへの割り当て\n",
    "全てのデータ点$X_n$を最も近い中心点$\\mu_k$に割り当てるコードを作成してください。\n",
    "\n",
    "\n",
    "K-menasにおける**近い**とは点と点のユークリッド距離が小さくなることです。ユークリッド距離とはピタゴラスの定理（三平方の定理）で求められるものですが、ベクトル$p, q$に対しては以下の数式で表現できます。\n",
    "\n",
    "$$\n",
    "\\|q-p\\| = \\sqrt{(q-p)\\cdot(q-p)}\n",
    "$$\n",
    "\n",
    "NumPyにはこの関数がnp.linalg.normとして用意されているため使用してください。\n",
    "\n",
    "\n",
    "[numpy.linalg.norm — NumPy v1.17 Manual](https://docs.scipy.org/doc/numpy/reference/generated/numpy.linalg.norm.html)\n",
    "\n",
    "\n",
    "中心点$\\mu_k$を固定した上でSSEを最小化していることになりますが、SSE自体を求める必要はありません。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "実数空間においては$\\|x\\|\\geq0$であるから、$\\|a\\|\\geq\\|b\\|$のとき$\\|a\\|^2\\geq\\|b\\|^2$もまた成り立つ。\n",
    "\n",
    "よって、簡単のためにユークリッド距離の比較は$\\|q-p\\|^2$を用いて行う。 -> `_each_diff_norm_squared(A, B)`\n",
    "```python\n",
    "    def _assign_cluster(self, X):\n",
    "        \"\"\"\n",
    "        データ点をもっとも近い中心点が属するクラスタに割り当てる\n",
    "        \"\"\"\n",
    "        # calc norm\n",
    "        _each_diff_norm = np.sqrt(self._each_diff_norm_squared(X, self.mu))\n",
    "\n",
    "        # one-hot\n",
    "        _r_binary = np.zeros((X.shape[0], self.n_clusters))\n",
    "        _r_binary[range(_r_binary.shape[0]), np.argmin(_each_diff_norm, axis=1)] = 1\n",
    "\n",
    "        return _r_binary\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題4】\n",
    "## 中心点の移動\n",
    "中心点$\\mu_k$を$k$番目のクラスタに割り当てられる全てのデータ点$X_n$の平均値（重心）に移動するコードを作成してください。\n",
    "\n",
    "\n",
    "クラスタの割り当て$r_{nk}$を固定した上でSSEを最小化していることになりますが、SSE自体を求める必要はありません。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}