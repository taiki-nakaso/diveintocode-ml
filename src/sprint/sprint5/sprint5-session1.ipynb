{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sprint\n",
    "## 機械学習スクラッチ SVM\n",
    "スクラッチでSVMを実装した後、学習と検証を行なっていきます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "分類のためのサポートベクターマシン（SVM、サポートベクトルマシン）のクラスをスクラッチで作成していきます。NumPyなど最低限のライブラリのみを使いアルゴリズムを実装していきます。\n",
    "\n",
    "\n",
    "SVMには学習時に分類の間違いを認めるソフトマージンSVMと、認めないハードマージンSVMがありますが、ここでは実装が単純なハードマージンSVMを扱います。\n",
    "\n",
    "\n",
    "以下に雛形を用意してあります。このScratchSVMClassifierクラスにコードを書き加えていってください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "class ScratchSVMClassifier():\n",
    "    \"\"\"\n",
    "    SVM分類器のスクラッチ実装\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    num_iter : int\n",
    "      イテレーション数\n",
    "    lr : float\n",
    "      学習率\n",
    "    kernel : str\n",
    "      カーネルの種類。線形カーネル（linear）か多項式カーネル（polly）\n",
    "    threshold : float\n",
    "      サポートベクターを選ぶための閾値\n",
    "    verbose : bool\n",
    "      学習過程を出力する場合はTrue\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    self.n_support_vectors : int\n",
    "      サポートベクターの数\n",
    "    self.index_support_vectors : 次の形のndarray, shape (n_support_vectors,)\n",
    "      サポートベクターのインデックス\n",
    "    self.X_sv :  次の形のndarray, shape(n_support_vectors, n_features)\n",
    "      サポートベクターの特徴量\n",
    "    self.lam_sv :  次の形のndarray, shape(n_support_vectors, 1)\n",
    "      サポートベクターの未定乗数\n",
    "    self.lam_all :  次の形のndarray, shape(n_samples, 1)\n",
    "      全ベクトルの未定乗数\n",
    "    self.y_sv :  次の形のndarray, shape(n_support_vectors, 1)\n",
    "      サポートベクターのラベル\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, num_iter, lr, kernel='linear', threshold=1e-5, verbose=False):\n",
    "        # ハイパーパラメータを属性として記録\n",
    "        self.iter = num_iter\n",
    "        self.lr = lr\n",
    "        self.kernel = kernel\n",
    "        self.threshold = threshold\n",
    "        self.verbose = verbose\n",
    "    def fit(self, X, y, X_val=None, y_val=None):\n",
    "        \"\"\"\n",
    "        SVM分類器を学習する。検証データが入力された場合はそれに対する精度もイテレーションごとに計算する。\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            訓練データの特徴量\n",
    "        y : 次の形のndarray, shape (n_samples, )\n",
    "            訓練データの正解値\n",
    "        X_val : 次の形のndarray, shape (n_samples, n_features)\n",
    "            検証データの特徴量\n",
    "        y_val : 次の形のndarray, shape (n_samples, )\n",
    "            検証データの正解値\n",
    "        \"\"\"\n",
    "        # preprocessing\n",
    "        n_samples = X.shape[0]\n",
    "        X_biased = np.concatenate((np.ones((n_samples, 1)), X), axis=1)\n",
    "        if self.kernel == 'linear':\n",
    "            _kernel = self._linear_kernel\n",
    "        else:\n",
    "            print(f'this model has no kernel named: {self._kernel}')\n",
    "            _kernel = self._linear_kernel\n",
    "        # 学習中のlamda保存用\n",
    "        self.lam_all = np.ones((n_samples, 1))\n",
    "\n",
    "        if self.verbose:\n",
    "            #verboseをTrueにした際は学習過程を出力\n",
    "            print('start learning')\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        # loop learning\n",
    "        for i in range(self.iter):\n",
    "            ## gradient ascent\n",
    "            self.lam_all = self._gradient_ascent(X_biased, y, _kernel)\n",
    "\n",
    "            ## pick support vectors\n",
    "            self.index_support_vectors = np.where(self.lam_all > self.threshold)[0]\n",
    "            self.n_support_vectors = len(self.index_support_vectors)\n",
    "            self.X_sv = X[self.index_support_vectors]\n",
    "            self.y_sv = y[self.index_support_vectors]\n",
    "            self.lam_sv = self.lam_all[self.index_support_vectors]\n",
    "\n",
    "            ## output process\n",
    "            if self.verbose:\n",
    "                print(f'{i+1} num of sv: {self.n_support_vectors}')\n",
    "        \n",
    "        end_time = time.time()\n",
    "        elapsed_time = end_time - start_time\n",
    "\n",
    "        print(f'{self.iter} Done! elapsed time: {elapsed_time:.5f}s')\n",
    "        \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        SVM分類器を使いラベルを推定する。\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            サンプル\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "            次の形のndarray, shape (n_samples, 1)\n",
    "            SVM分類器による推定結果\n",
    "        \"\"\"\n",
    "        # preprocessing\n",
    "        n_samples = X.shape[0]\n",
    "        X_biased = np.concatenate((np.ones((n_samples, 1)), X), axis=1)\n",
    "        if self.kernel == 'linear':\n",
    "            _kernel = self._linear_kernel\n",
    "        else:\n",
    "            print(f'this model has no kernel named: {self._kernel}')\n",
    "            _kernel = self._linear_kernel\n",
    "\n",
    "        y_pred = self.lam_sv * self.y_sv * _kernel(self.X_sv, X_biased)\n",
    "\n",
    "        return y_pred\n",
    "\n",
    "    def _linear_kernel(self, xi, xj):\n",
    "        \"\"\"\n",
    "        線形カーネル関数\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        xi, xj : 次の形のndarray, shape (n_features,)\n",
    "            サンプル\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "            int\n",
    "            線形カーネル関数の出力結果\n",
    "        \"\"\"\n",
    "        k = np.matmul(xi, xj.T)\n",
    "\n",
    "        return k\n",
    "    \n",
    "    def _gradient_ascent(self, X, y, k):\n",
    "        \"\"\"\n",
    "        ラグランジュ乗数の値を更新する\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            訓練データの特徴量\n",
    "        y : 次の形のndarray, shape (n_samples, )\n",
    "            訓練データの正解値\n",
    "        k \n",
    "            カーネル関数\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        lam_new: 次の形のndarray, shape(n_samples, 1)\n",
    "            更新された新たな未定乗数\n",
    "        \"\"\"\n",
    "        # get kernel value\n",
    "        k_val = k(X, X)\n",
    "        y_new = y.reshape(-1, 1)\n",
    "\n",
    "        # update lambda\n",
    "        lam_new = self.lam_all + self.lr*(1 - (y_new * (np.sum(self.lam_all * y_new * k_val, axis=0).reshape(-1, 1))))\n",
    "\n",
    "        # replace lambda\n",
    "        lam_new = np.where(lam_new < 0, 0, lam_new)\n",
    "\n",
    "        return lam_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題1】\n",
    "## ラグランジュの未定乗数法による最急降下\n",
    "SVMの学習は、ラグランジュの未定乗数法を用います。サンプル数分のラグランジュ乗数 $\\lambda$ を用意して、以下の式により更新していきます。この計算を行うメソッドをScratchSVMClassifierクラスに実装してください。\n",
    "\n",
    "$$\n",
    "\\lambda_i^{new} = \\lambda_i + \\alpha(1 - \\sum_{j=1}^{n}{\\lambda_j y_i y_j k(x_i, x_j)})\n",
    "$$\n",
    "\n",
    "ここで $k(x_i, x_j)$ はカーネル関数です。線形カーネルの場合は次のようになります。他のカーネル関数にも対応できるように、この部分は独立したメソッドとしておきましょう。\n",
    "\n",
    "$$\n",
    "k(x_i, x_j) = x_{i}^{T} x_j\n",
    "$$\n",
    "\n",
    "条件として、更新毎に $\\lambda_i >= 0$を満たす必要があります。満たさない場合は $\\lambda_i = 0$とします。\n",
    "\n",
    "\n",
    "$i, j$ : サンプルのインデックス\n",
    "\n",
    "\n",
    "$\\lambda_i^{new}$ : 更新後のi番目のサンプルのラグランジュ乗数\n",
    "\n",
    "\n",
    "$\\lambda_i$ : 更新前のi番目のサンプルのラグランジュ乗数\n",
    "\n",
    "\n",
    "$\\alpha$ : 学習率\n",
    "\n",
    "\n",
    "$\\lambda_j$ : j番目のサンプルのラグランジュ乗数\n",
    "\n",
    "\n",
    "$y_i$ : i番目のサンプルのラベル\n",
    "\n",
    "\n",
    "$y_j$ : j番目のサンプルのラベル\n",
    "\n",
    "\n",
    "$x_i$ : i番目のサンプルの特徴量ベクトル\n",
    "\n",
    "\n",
    "$x_j$ : j番目のサンプルの特徴量ベクトル\n",
    "\n",
    "\n",
    "あるサンプルに対しての全てのサンプルとの関係を計算していくことになります。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "    def _linear_kernel(self, xi, xj):\n",
    "        \"\"\"\n",
    "        線形カーネル関数\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        xi, xj : 次の形のndarray, shape (n_features,)\n",
    "            サンプル\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "            int\n",
    "            線形カーネル関数の出力結果\n",
    "        \"\"\"\n",
    "        k = np.matmul(xi, xj.T)\n",
    "\n",
    "        return k\n",
    "    \n",
    "    def _linear_ascent(self, X, y, k):\n",
    "        \"\"\"\n",
    "        パラメータベクトルの値を更新する\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            訓練データの特徴量\n",
    "        y : 次の形のndarray, shape (n_samples, )\n",
    "            訓練データの正解値\n",
    "        k \n",
    "            カーネル関数\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        lam_sv_new: 次の形のndarray, shape(n_support_vectors, 1)\n",
    "            更新された新たな未定乗数\n",
    "        \"\"\"\n",
    "        # get kernxel value\n",
    "        k_val = k(self.x_sv[1:], self.x_sv.T)\n",
    "\n",
    "        # update lambda\n",
    "        lam_sv_new = self.lam_sv + self.lr(1 - (self.y_sv * (np.sum(self.lam_sv[1:] * self.y_sv[1:] * k, axis=0).T))\n",
    "\n",
    "        # replace lambda\n",
    "        lam_sv_new = np.where(lam_sv_new < 0, 0, lam_sv_new)\n",
    "\n",
    "        return lam_sv_new\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題2】\n",
    "## サポートベクターの決定\n",
    "計算したラグランジュ乗数$λ$が設定した閾値より大きいサンプルをサポートベクターとして扱います。推定時にサポートベクターが必要になります。サポートベクターを決定し、インスタンス変数として保持しておくコードを書いてください。\n",
    "\n",
    "閾値はハイパーパラメータですが、1e-5程度からはじめると良いでしょう。サポートベクターの数を出力させられるようにしておくと学習がうまく行えているかを確認できます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "def fit(self, X, y, X_val=None, y_val=None):\n",
    "        \"\"\"\n",
    "        SVM分類器を学習する。検証データが入力された場合はそれに対する精度もイテレーションごとに計算する。\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            訓練データの特徴量\n",
    "        y : 次の形のndarray, shape (n_samples, )\n",
    "            訓練データの正解値\n",
    "        X_val : 次の形のndarray, shape (n_samples, n_features)\n",
    "            検証データの特徴量\n",
    "        y_val : 次の形のndarray, shape (n_samples, )\n",
    "            検証データの正解値\n",
    "        \"\"\"\n",
    "        # preprocessing\n",
    "        n_samples = X.shape[0]\n",
    "        X_biased = np.concatenate((np.ones(n_samples, 1)), X), axis=1)\n",
    "        if self.kernel == 'linear':\n",
    "            _kernel = self._linear_kernel\n",
    "        else:\n",
    "            print(f'this model has no kernel named: {self._kernel}')\n",
    "            _kernel = self._linear_kernel\n",
    "        # 学習中のlamda保存用\n",
    "        self.lam_all = np.ones((n_samples, 1))\n",
    "\n",
    "        if self.verbose:\n",
    "            #verboseをTrueにした際は学習過程を出力\n",
    "            print('start learning'))\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        # loop learning\n",
    "        for i in range(self.iter):\n",
    "            ## gradient ascent\n",
    "            lam_all = self._gradient_ascent(X_biased, y, _kernel)\n",
    "\n",
    "            ## pick support vectors\n",
    "            self.index_support_vectors = np.where(lam_all > self.thereshold)\n",
    "            self.n_support_vectors = self.index_support_vectors.shape[0]\n",
    "            self.X_sv = X[self.index_support_vectors]\n",
    "            self.y_sv = y[self.index_support_vectors]\n",
    "            self.lam_sv = lam_all[self.index_support_vectors]\n",
    "\n",
    "            ## output process\n",
    "            if self.verbose:\n",
    "                print(f'{i+1} num of sv: {self.n_support_vectors}')\n",
    "        \n",
    "        end_time = time.time()\n",
    "        elapsed_time = end_time - start_time\n",
    "        \n",
    "        print(f'Done! elapsed time: {elapsed_time:.5f}s')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題3】\n",
    "## 推定\n",
    "推定時には、推定したいデータの特徴量とサポートベクターの特徴量をカーネル関数によって計算します。求めた$f(x)$の符号が分類結果です。\n",
    "\n",
    "$$\n",
    "f(x) = \\sum_{n=1}^{N}\\lambda_n y_{sv_n} k(x, s_n)\n",
    "$$\n",
    " \n",
    "$x$ : 推定したいデータの特徴量ベクトル\n",
    "\n",
    "\n",
    "$N$ : サポートベクターの数\n",
    "\n",
    "\n",
    "$n$ : サポートベクターのインデックス\n",
    "\n",
    "\n",
    "$λ_n$ : $n$番目のサポートベクターのラグランジュ乗数\n",
    "\n",
    "\n",
    "$y_{sv_n}$ : n番目のサポートベクターのラベル\n",
    "\n",
    "\n",
    "$k()$ : カーネル関数\n",
    "\n",
    "\n",
    "$s_n$ : n番目のサポートベクターの特徴量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        SVM分類器を使いラベルを推定する。\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            サンプル\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "            次の形のndarray, shape (n_samples, 1)\n",
    "            SVM分類器による推定結果\n",
    "        \"\"\"\n",
    "        # preprocessing\n",
    "        #n_samples = X.shape[0]\n",
    "        X_biased = np.concatenate((np.ones((n_samples, 1)), X), axis=1)\n",
    "        if self.kernel == 'linear':\n",
    "            _kernel = self._linear_kernel\n",
    "        else:\n",
    "            print(f'this model has no kernel named: {self._kernel}')\n",
    "            _kernel = self._linear_kernel\n",
    "\n",
    "        y_pred = self.lam_sv * self.y_sv * _kernel(self.X_sv, X_biased)\n",
    "\n",
    "        return y_pred\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題4】\n",
    "## 学習と推定\n",
    "機械学習スクラッチ入門のSprintで用意したシンプルデータセット1の2値分類に対してスクラッチ実装の学習と推定を行なってください。\n",
    "\n",
    "scikit-learnによる実装と比べ、正しく動いているかを確認してください。\n",
    "\n",
    "AccuracyやPrecision、Recallなどの指標値はscikit-learnを使用してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# シンプルデータセット1\n",
    "np.random.seed(seed=0)\n",
    "n_samples = 500\n",
    "f0 = [-1, 2]\n",
    "f1 = [2, -1]\n",
    "cov = [[1.0,0.8], [0.8, 1.0]]\n",
    "f0 = np.random.multivariate_normal(f0, cov, int(n_samples/2))\n",
    "f1 = np.random.multivariate_normal(f1, cov, int(n_samples/2))\n",
    "X = np.concatenate((f0, f1))\n",
    "y = np.concatenate((np.ones((int(n_samples/2))), np.ones((int(n_samples/2))) *(-1))).astype(np.int)\n",
    "random_index = np.random.permutation(np.arange(n_samples))\n",
    "X = X[random_index]\n",
    "y = y[random_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_std = scaler.transform(X_train)\n",
    "X_test_std = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": ": 7\n1892 num of sv: 7\n1893 num of sv: 7\n1894 num of sv: 7\n1895 num of sv: 7\n1896 num of sv: 7\n1897 num of sv: 7\n1898 num of sv: 7\n1899 num of sv: 7\n1900 num of sv: 7\n1901 num of sv: 7\n1902 num of sv: 7\n1903 num of sv: 7\n1904 num of sv: 7\n1905 num of sv: 7\n1906 num of sv: 7\n1907 num of sv: 7\n1908 num of sv: 7\n1909 num of sv: 7\n1910 num of sv: 7\n1911 num of sv: 7\n1912 num of sv: 7\n1913 num of sv: 7\n1914 num of sv: 7\n1915 num of sv: 7\n1916 num of sv: 7\n1917 num of sv: 7\n1918 num of sv: 7\n1919 num of sv: 7\n1920 num of sv: 7\n1921 num of sv: 7\n1922 num of sv: 7\n1923 num of sv: 7\n1924 num of sv: 7\n1925 num of sv: 7\n1926 num of sv: 7\n1927 num of sv: 7\n1928 num of sv: 7\n1929 num of sv: 7\n1930 num of sv: 7\n1931 num of sv: 7\n1932 num of sv: 7\n1933 num of sv: 7\n1934 num of sv: 7\n1935 num of sv: 7\n1936 num of sv: 7\n1937 num of sv: 7\n1938 num of sv: 7\n1939 num of sv: 7\n1940 num of sv: 7\n1941 num of sv: 7\n1942 num of sv: 7\n1943 num of sv: 7\n1944 num of sv: 7\n1945 num of sv: 7\n1946 num of sv: 7\n1947 num of sv: 7\n1948 num of sv: 7\n1949 num of sv: 7\n1950 num of sv: 7\n1951 num of sv: 7\n1952 num of sv: 7\n1953 num of sv: 7\n1954 num of sv: 7\n1955 num of sv: 7\n1956 num of sv: 7\n1957 num of sv: 7\n1958 num of sv: 7\n1959 num of sv: 7\n1960 num of sv: 7\n1961 num of sv: 7\n1962 num of sv: 7\n1963 num of sv: 7\n1964 num of sv: 7\n1965 num of sv: 7\n1966 num of sv: 7\n1967 num of sv: 7\n1968 num of sv: 7\n1969 num of sv: 7\n1970 num of sv: 7\n1971 num of sv: 7\n1972 num of sv: 7\n1973 num of sv: 7\n1974 num of sv: 7\n1975 num of sv: 7\n1976 num of sv: 7\n1977 num of sv: 7\n1978 num of sv: 7\n1979 num of sv: 7\n1980 num of sv: 7\n1981 num of sv: 7\n1982 num of sv: 7\n1983 num of sv: 7\n1984 num of sv: 7\n1985 num of sv: 7\n1986 num of sv: 7\n1987 num of sv: 7\n1988 num of sv: 7\n1989 num of sv: 7\n1990 num of sv: 7\n1991 num of sv: 7\n1992 num of sv: 7\n1993 num of sv: 7\n1994 num of sv: 7\n1995 num of sv: 7\n1996 num of sv: 7\n1997 num of sv: 7\n1998 num of sv: 7\n1999 num of sv: 7\n2000 num of sv: 7\n2001 num of sv: 7\n2002 num of sv: 7\n2003 num of sv: 7\n2004 num of sv: 7\n2005 num of sv: 7\n2006 num of sv: 7\n2007 num of sv: 7\n2008 num of sv: 7\n2009 num of sv: 7\n2010 num of sv: 7\n2011 num of sv: 7\n2012 num of sv: 7\n2013 num of sv: 7\n2014 num of sv: 7\n2015 num of sv: 7\n2016 num of sv: 7\n2017 num of sv: 7\n2018 num of sv: 7\n2019 num of sv: 7\n2020 num of sv: 7\n2021 num of sv: 7\n2022 num of sv: 7\n2023 num of sv: 7\n2024 num of sv: 7\n2025 num of sv: 7\n2026 num of sv: 7\n2027 num of sv: 7\n2028 num of sv: 7\n2029 num of sv: 7\n2030 num of sv: 7\n2031 num of sv: 7\n2032 num of sv: 7\n2033 num of sv: 7\n2034 num of sv: 7\n2035 num of sv: 7\n2036 num of sv: 7\n2037 num of sv: 7\n2038 num of sv: 7\n2039 num of sv: 7\n2040 num of sv: 7\n2041 num of sv: 7\n2042 num of sv: 7\n2043 num of sv: 7\n2044 num of sv: 7\n2045 num of sv: 7\n2046 num of sv: 7\n2047 num of sv: 7\n2048 num of sv: 7\n2049 num of sv: 7\n2050 num of sv: 7\n2051 num of sv: 7\n2052 num of sv: 7\n2053 num of sv: 7\n2054 num of sv: 7\n2055 num of sv: 7\n2056 num of sv: 7\n2057 num of sv: 7\n2058 num of sv: 7\n2059 num of sv: 7\n2060 num of sv: 7\n2061 num of sv: 7\n2062 num of sv: 7\n2063 num of sv: 7\n2064 num of sv: 7\n2065 num of sv: 7\n2066 num of sv: 7\n2067 num of sv: 7\n2068 num of sv: 7\n2069 num of sv: 7\n2070 num of sv: 7\n2071 num of sv: 7\n2072 num of sv: 7\n2073 num of sv: 7\n2074 num of sv: 7\n2075 num of sv: 7\n2076 num of sv: 7\n2077 num of sv: 7\n2078 num of sv: 7\n2079 num of sv: 7\n2080 num of sv: 7\n2081 num of sv: 7\n2082 num of sv: 7\n2083 num of sv: 7\n2084 num of sv: 7\n2085 num of sv: 7\n2086 num of sv: 7\n2087 num of sv: 7\n2088 num of sv: 7\n2089 num of sv: 7\n2090 num of sv: 7\n2091 num of sv: 7\n2092 num of sv: 7\n2093 num of sv: 7\n2094 num of sv: 7\n2095 num of sv: 7\n2096 num of sv: 7\n2097 num of sv: 7\n2098 num of sv: 7\n2099 num of sv: 7\n2100 num of sv: 7\n2101 num of sv: 7\n2102 num of sv: 7\n2103 num of sv: 7\n2104 num of sv: 7\n2105 num of sv: 7\n2106 num of sv: 7\n2107 num of sv: 7\n2108 num of sv: 7\n2109 num of sv: 7\n2110 num of sv: 7\n2111 num of sv: 7\n2112 num of sv: 7\n2113 num of sv: 7\n2114 num of sv: 7\n2115 num of sv: 7\n2116 num of sv: 7\n2117 num of sv: 7\n2118 num of sv: 7\n2119 num of sv: 7\n2120 num of sv: 7\n2121 num of sv: 7\n2122 num of sv: 7\n2123 num of sv: 7\n2124 num of sv: 7\n2125 num of sv: 7\n2126 num of sv: 7\n2127 num of sv: 7\n2128 num of sv: 7\n2129 num of sv: 7\n2130 num of sv: 7\n2131 num of sv: 7\n2132 num of sv: 7\n2133 num of sv: 7\n2134 num of sv: 7\n2135 num of sv: 7\n2136 num of sv: 7\n2137 num of sv: 7\n2138 num of sv: 7\n2139 num of sv: 7\n2140 num of sv: 7\n2141 num of sv: 7\n2142 num of sv: 7\n2143 num of sv: 7\n2144 num of sv: 7\n2145 num of sv: 7\n2146 num of sv: 7\n2147 num of sv: 7\n2148 num of sv: 7\n2149 num of sv: 7\n2150 num of sv: 7\n2151 num of sv: 7\n2152 num of sv: 7\n2153 num of sv: 7\n2154 num of sv: 7\n2155 num of sv: 7\n2156 num of sv: 7\n2157 num of sv: 7\n2158 num of sv: 7\n2159 num of sv: 7\n2160 num of sv: 7\n2161 num of sv: 7\n2162 num of sv: 7\n2163 num of sv: 7\n2164 num of sv: 7\n2165 num of sv: 7\n2166 num of sv: 7\n2167 num of sv: 7\n2168 num of sv: 7\n2169 num of sv: 7\n2170 num of sv: 7\n2171 num of sv: 7\n2172 num of sv: 7\n2173 num of sv: 7\n2174 num of sv: 7\n2175 num of sv: 7\n2176 num of sv: 7\n2177 num of sv: 7\n2178 num of sv: 7\n2179 num of sv: 7\n2180 num of sv: 7\n2181 num of sv: 7\n2182 num of sv: 7\n2183 num of sv: 7\n2184 num of sv: 7\n2185 num of sv: 7\n2186 num of sv: 7\n2187 num of sv: 7\n2188 num of sv: 7\n2189 num of sv: 7\n2190 num of sv: 7\n2191 num of sv: 7\n2192 num of sv: 7\n2193 num of sv: 7\n2194 num of sv: 7\n2195 num of sv: 7\n2196 num of sv: 7\n2197 num of sv: 7\n2198 num of sv: 7\n2199 num of sv: 7\n2200 num of sv: 7\n2201 num of sv: 7\n2202 num of sv: 7\n2203 num of sv: 7\n2204 num of sv: 7\n2205 num of sv: 7\n2206 num of sv: 7\n2207 num of sv: 7\n2208 num of sv: 7\n2209 num of sv: 7\n2210 num of sv: 7\n2211 num of sv: 7\n2212 num of sv: 7\n2213 num of sv: 7\n2214 num of sv: 7\n2215 num of sv: 7\n2216 num of sv: 7\n2217 num of sv: 7\n2218 num of sv: 7\n2219 num of sv: 7\n2220 num of sv: 7\n2221 num of sv: 7\n2222 num of sv: 7\n2223 num of sv: 7\n2224 num of sv: 7\n2225 num of sv: 7\n2226 num of sv: 7\n2227 num of sv: 7\n2228 num of sv: 7\n2229 num of sv: 7\n2230 num of sv: 7\n2231 num of sv: 7\n2232 num of sv: 7\n2233 num of sv: 7\n2234 num of sv: 6\n2235 num of sv: 6\n2236 num of sv: 6\n2237 num of sv: 6\n2238 num of sv: 6\n2239 num of sv: 6\n2240 num of sv: 6\n2241 num of sv: 6\n2242 num of sv: 6\n2243 num of sv: 6\n2244 num of sv: 6\n2245 num of sv: 6\n2246 num of sv: 6\n2247 num of sv: 6\n2248 num of sv: 6\n2249 num of sv: 6\n2250 num of sv: 6\n2251 num of sv: 6\n2252 num of sv: 6\n2253 num of sv: 6\n2254 num of sv: 6\n2255 num of sv: 6\n2256 num of sv: 6\n2257 num of sv: 6\n2258 num of sv: 6\n2259 num of sv: 6\n2260 num of sv: 6\n2261 num of sv: 6\n2262 num of sv: 6\n2263 num of sv: 6\n2264 num of sv: 6\n2265 num of sv: 6\n2266 num of sv: 6\n2267 num of sv: 6\n2268 num of sv: 6\n2269 num of sv: 6\n2270 num of sv: 6\n2271 num of sv: 6\n2272 num of sv: 6\n2273 num of sv: 6\n2274 num of sv: 6\n2275 num of sv: 6\n2276 num of sv: 6\n2277 num of sv: 6\n2278 num of sv: 6\n2279 num of sv: 6\n2280 num of sv: 6\n2281 num of sv: 6\n2282 num of sv: 6\n2283 num of sv: 6\n2284 num of sv: 6\n2285 num of sv: 6\n2286 num of sv: 6\n2287 num of sv: 6\n2288 num of sv: 6\n2289 num of sv: 6\n2290 num of sv: 6\n2291 num of sv: 6\n2292 num of sv: 6\n2293 num of sv: 6\n2294 num of sv: 6\n2295 num of sv: 6\n2296 num of sv: 6\n2297 num of sv: 6\n2298 num of sv: 6\n2299 num of sv: 6\n2300 num of sv: 6\n2301 num of sv: 6\n2302 num of sv: 6\n2303 num of sv: 6\n2304 num of sv: 6\n2305 num of sv: 6\n2306 num of sv: 6\n2307 num of sv: 6\n2308 num of sv: 6\n2309 num of sv: 6\n2310 num of sv: 6\n2311 num of sv: 6\n2312 num of sv: 6\n2313 num of sv: 6\n2314 num of sv: 6\n2315 num of sv: 6\n2316 num of sv: 6\n2317 num of sv: 6\n2318 num of sv: 6\n2319 num of sv: 6\n2320 num of sv: 6\n2321 num of sv: 6\n2322 num of sv: 6\n2323 num of sv: 6\n2324 num of sv: 6\n2325 num of sv: 6\n2326 num of sv: 6\n2327 num of sv: 6\n2328 num of sv: 6\n2329 num of sv: 6\n2330 num of sv: 6\n2331 num of sv: 6\n2332 num of sv: 6\n2333 num of sv: 6\n2334 num of sv: 6\n2335 num of sv: 6\n2336 num of sv: 6\n2337 num of sv: 6\n2338 num of sv: 6\n2339 num of sv: 6\n2340 num of sv: 6\n2341 num of sv: 6\n2342 num of sv: 6\n2343 num of sv: 6\n2344 num of sv: 6\n2345 num of sv: 6\n2346 num of sv: 6\n2347 num of sv: 6\n2348 num of sv: 6\n2349 num of sv: 6\n2350 num of sv: 6\n2351 num of sv: 6\n2352 num of sv: 6\n2353 num of sv: 6\n2354 num of sv: 6\n2355 num of sv: 6\n2356 num of sv: 6\n2357 num of sv: 6\n2358 num of sv: 6\n2359 num of sv: 6\n2360 num of sv: 6\n2361 num of sv: 6\n2362 num of sv: 6\n2363 num of sv: 6\n2364 num of sv: 6\n2365 num of sv: 6\n2366 num of sv: 6\n2367 num of sv: 6\n2368 num of sv: 6\n2369 num of sv: 6\n2370 num of sv: 6\n2371 num of sv: 6\n2372 num of sv: 6\n2373 num of sv: 6\n2374 num of sv: 6\n2375 num of sv: 6\n2376 num of sv: 6\n2377 num of sv: 6\n2378 num of sv: 6\n2379 num of sv: 6\n2380 num of sv: 6\n2381 num of sv: 6\n2382 num of sv: 6\n2383 num of sv: 6\n2384 num of sv: 6\n2385 num of sv: 6\n2386 num of sv: 6\n2387 num of sv: 6\n2388 num of sv: 6\n2389 num of sv: 6\n2390 num of sv: 6\n2391 num of sv: 6\n2392 num of sv: 6\n2393 num of sv: 6\n2394 num of sv: 6\n2395 num of sv: 6\n2396 num of sv: 6\n2397 num of sv: 6\n2398 num of sv: 6\n2399 num of sv: 6\n2400 num of sv: 6\n2401 num of sv: 6\n2402 num of sv: 6\n2403 num of sv: 6\n2404 num of sv: 6\n2405 num of sv: 6\n2406 num of sv: 6\n2407 num of sv: 6\n2408 num of sv: 6\n2409 num of sv: 6\n2410 num of sv: 6\n2411 num of sv: 6\n2412 num of sv: 6\n2413 num of sv: 6\n2414 num of sv: 6\n2415 num of sv: 6\n2416 num of sv: 6\n2417 num of sv: 6\n2418 num of sv: 6\n2419 num of sv: 6\n2420 num of sv: 6\n2421 num of sv: 6\n2422 num of sv: 6\n2423 num of sv: 6\n2424 num of sv: 6\n2425 num of sv: 6\n2426 num of sv: 6\n2427 num of sv: 6\n2428 num of sv: 6\n2429 num of sv: 6\n2430 num of sv: 6\n2431 num of sv: 6\n2432 num of sv: 6\n2433 num of sv: 6\n2434 num of sv: 6\n2435 num of sv: 6\n2436 num of sv: 6\n2437 num of sv: 6\n2438 num of sv: 6\n2439 num of sv: 6\n2440 num of sv: 6\n2441 num of sv: 6\n2442 num of sv: 6\n2443 num of sv: 6\n2444 num of sv: 6\n2445 num of sv: 6\n2446 num of sv: 6\n2447 num of sv: 6\n2448 num of sv: 6\n2449 num of sv: 6\n2450 num of sv: 6\n2451 num of sv: 6\n2452 num of sv: 6\n2453 num of sv: 6\n2454 num of sv: 6\n2455 num of sv: 6\n2456 num of sv: 6\n2457 num of sv: 6\n2458 num of sv: 6\n2459 num of sv: 6\n2460 num of sv: 6\n2461 num of sv: 6\n2462 num of sv: 6\n2463 num of sv: 6\n2464 num of sv: 6\n2465 num of sv: 6\n2466 num of sv: 6\n2467 num of sv: 6\n2468 num of sv: 6\n2469 num of sv: 6\n2470 num of sv: 6\n2471 num of sv: 6\n2472 num of sv: 6\n2473 num of sv: 6\n2474 num of sv: 6\n2475 num of sv: 6\n2476 num of sv: 6\n2477 num of sv: 6\n2478 num of sv: 6\n2479 num of sv: 6\n2480 num of sv: 6\n2481 num of sv: 6\n2482 num of sv: 6\n2483 num of sv: 6\n2484 num of sv: 6\n2485 num of sv: 6\n2486 num of sv: 6\n2487 num of sv: 6\n2488 num of sv: 6\n2489 num of sv: 6\n2490 num of sv: 6\n2491 num of sv: 6\n2492 num of sv: 6\n2493 num of sv: 6\n2494 num of sv: 6\n2495 num of sv: 6\n2496 num of sv: 6\n2497 num of sv: 6\n2498 num of sv: 6\n2499 num of sv: 6\n2500 num of sv: 6\n2501 num of sv: 6\n2502 num of sv: 6\n2503 num of sv: 6\n2504 num of sv: 6\n2505 num of sv: 6\n2506 num of sv: 6\n2507 num of sv: 6\n2508 num of sv: 6\n2509 num of sv: 6\n2510 num of sv: 6\n2511 num of sv: 6\n2512 num of sv: 6\n2513 num of sv: 6\n2514 num of sv: 6\n2515 num of sv: 6\n2516 num of sv: 6\n2517 num of sv: 6\n2518 num of sv: 6\n2519 num of sv: 6\n2520 num of sv: 6\n2521 num of sv: 6\n2522 num of sv: 6\n2523 num of sv: 6\n2524 num of sv: 6\n2525 num of sv: 6\n2526 num of sv: 6\n2527 num of sv: 6\n2528 num of sv: 6\n2529 num of sv: 6\n2530 num of sv: 6\n2531 num of sv: 6\n2532 num of sv: 6\n2533 num of sv: 6\n2534 num of sv: 6\n2535 num of sv: 6\n2536 num of sv: 6\n2537 num of sv: 6\n2538 num of sv: 6\n2539 num of sv: 6\n2540 num of sv: 6\n2541 num of sv: 6\n2542 num of sv: 6\n2543 num of sv: 6\n2544 num of sv: 6\n2545 num of sv: 6\n2546 num of sv: 6\n2547 num of sv: 6\n2548 num of sv: 6\n2549 num of sv: 6\n2550 num of sv: 6\n2551 num of sv: 6\n2552 num of sv: 6\n2553 num of sv: 6\n2554 num of sv: 6\n2555 num of sv: 6\n2556 num of sv: 6\n2557 num of sv: 6\n2558 num of sv: 6\n2559 num of sv: 6\n2560 num of sv: 6\n2561 num of sv: 6\n2562 num of sv: 6\n2563 num of sv: 6\n2564 num of sv: 6\n2565 num of sv: 6\n2566 num of sv: 6\n2567 num of sv: 6\n2568 num of sv: 6\n2569 num of sv: 6\n2570 num of sv: 6\n2571 num of sv: 6\n2572 num of sv: 6\n2573 num of sv: 6\n2574 num of sv: 6\n2575 num of sv: 6\n2576 num of sv: 6\n2577 num of sv: 6\n2578 num of sv: 6\n2579 num of sv: 6\n2580 num of sv: 6\n2581 num of sv: 6\n2582 num of sv: 6\n2583 num of sv: 6\n2584 num of sv: 6\n2585 num of sv: 6\n2586 num of sv: 6\n2587 num of sv: 6\n2588 num of sv: 6\n2589 num of sv: 6\n2590 num of sv: 6\n2591 num of sv: 6\n2592 num of sv: 6\n2593 num of sv: 6\n2594 num of sv: 6\n2595 num of sv: 6\n2596 num of sv: 6\n2597 num of sv: 6\n2598 num of sv: 6\n2599 num of sv: 6\n2600 num of sv: 6\n2601 num of sv: 6\n2602 num of sv: 6\n2603 num of sv: 6\n2604 num of sv: 6\n2605 num of sv: 6\n2606 num of sv: 6\n2607 num of sv: 6\n2608 num of sv: 6\n2609 num of sv: 6\n2610 num of sv: 6\n2611 num of sv: 6\n2612 num of sv: 6\n2613 num of sv: 6\n2614 num of sv: 6\n2615 num of sv: 6\n2616 num of sv: 6\n2617 num of sv: 6\n2618 num of sv: 6\n2619 num of sv: 6\n2620 num of sv: 6\n2621 num of sv: 6\n2622 num of sv: 6\n2623 num of sv: 6\n2624 num of sv: 6\n2625 num of sv: 6\n2626 num of sv: 6\n2627 num of sv: 6\n2628 num of sv: 6\n2629 num of sv: 6\n2630 num of sv: 6\n2631 num of sv: 6\n2632 num of sv: 6\n2633 num of sv: 6\n2634 num of sv: 6\n2635 num of sv: 6\n2636 num of sv: 6\n2637 num of sv: 6\n2638 num of sv: 6\n2639 num of sv: 6\n2640 num of sv: 6\n2641 num of sv: 6\n2642 num of sv: 6\n2643 num of sv: 6\n2644 num of sv: 6\n2645 num of sv: 6\n2646 num of sv: 6\n2647 num of sv: 6\n2648 num of sv: 6\n2649 num of sv: 6\n2650 num of sv: 6\n2651 num of sv: 6\n2652 num of sv: 6\n2653 num of sv: 6\n2654 num of sv: 6\n2655 num of sv: 6\n2656 num of sv: 6\n2657 num of sv: 6\n2658 num of sv: 6\n2659 num of sv: 6\n2660 num of sv: 6\n2661 num of sv: 6\n2662 num of sv: 6\n2663 num of sv: 6\n2664 num of sv: 6\n2665 num of sv: 6\n2666 num of sv: 6\n2667 num of sv: 6\n2668 num of sv: 6\n2669 num of sv: 6\n2670 num of sv: 6\n2671 num of sv: 6\n2672 num of sv: 6\n2673 num of sv: 6\n2674 num of sv: 6\n2675 num of sv: 6\n2676 num of sv: 6\n2677 num of sv: 6\n2678 num of sv: 6\n2679 num of sv: 6\n2680 num of sv: 6\n2681 num of sv: 6\n2682 num of sv: 6\n2683 num of sv: 6\n2684 num of sv: 6\n2685 num of sv: 6\n2686 num of sv: 6\n2687 num of sv: 6\n2688 num of sv: 6\n2689 num of sv: 6\n2690 num of sv: 6\n2691 num of sv: 6\n2692 num of sv: 6\n2693 num of sv: 6\n2694 num of sv: 6\n2695 num of sv: 6\n2696 num of sv: 6\n2697 num of sv: 6\n2698 num of sv: 6\n2699 num of sv: 6\n2700 num of sv: 6\n2701 num of sv: 6\n2702 num of sv: 6\n2703 num of sv: 6\n2704 num of sv: 6\n2705 num of sv: 6\n2706 num of sv: 6\n2707 num of sv: 6\n2708 num of sv: 6\n2709 num of sv: 6\n2710 num of sv: 6\n2711 num of sv: 6\n2712 num of sv: 6\n2713 num of sv: 6\n2714 num of sv: 6\n2715 num of sv: 6\n2716 num of sv: 6\n2717 num of sv: 6\n2718 num of sv: 6\n2719 num of sv: 6\n2720 num of sv: 6\n2721 num of sv: 6\n2722 num of sv: 6\n2723 num of sv: 6\n2724 num of sv: 6\n2725 num of sv: 6\n2726 num of sv: 6\n2727 num of sv: 6\n2728 num of sv: 6\n2729 num of sv: 6\n2730 num of sv: 6\n2731 num of sv: 6\n2732 num of sv: 6\n2733 num of sv: 6\n2734 num of sv: 6\n2735 num of sv: 6\n2736 num of sv: 6\n2737 num of sv: 6\n2738 num of sv: 6\n2739 num of sv: 6\n2740 num of sv: 6\n2741 num of sv: 6\n2742 num of sv: 6\n2743 num of sv: 6\n2744 num of sv: 6\n2745 num of sv: 6\n2746 num of sv: 6\n2747 num of sv: 6\n2748 num of sv: 6\n2749 num of sv: 6\n2750 num of sv: 6\n2751 num of sv: 6\n2752 num of sv: 6\n2753 num of sv: 6\n2754 num of sv: 6\n2755 num of sv: 6\n2756 num of sv: 6\n2757 num of sv: 6\n2758 num of sv: 6\n2759 num of sv: 6\n2760 num of sv: 6\n2761 num of sv: 6\n2762 num of sv: 6\n2763 num of sv: 6\n2764 num of sv: 6\n2765 num of sv: 6\n2766 num of sv: 6\n2767 num of sv: 6\n2768 num of sv: 6\n2769 num of sv: 6\n2770 num of sv: 6\n2771 num of sv: 6\n2772 num of sv: 6\n2773 num of sv: 6\n2774 num of sv: 6\n2775 num of sv: 6\n2776 num of sv: 6\n2777 num of sv: 6\n2778 num of sv: 6\n2779 num of sv: 6\n2780 num of sv: 6\n2781 num of sv: 6\n2782 num of sv: 6\n2783 num of sv: 6\n2784 num of sv: 6\n2785 num of sv: 6\n2786 num of sv: 6\n2787 num of sv: 6\n2788 num of sv: 6\n2789 num of sv: 6\n2790 num of sv: 6\n2791 num of sv: 6\n2792 num of sv: 6\n2793 num of sv: 6\n2794 num of sv: 6\n2795 num of sv: 6\n2796 num of sv: 6\n2797 num of sv: 6\n2798 num of sv: 6\n2799 num of sv: 6\n2800 num of sv: 6\n2801 num of sv: 6\n2802 num of sv: 6\n2803 num of sv: 6\n2804 num of sv: 6\n2805 num of sv: 6\n2806 num of sv: 6\n2807 num of sv: 6\n2808 num of sv: 6\n2809 num of sv: 6\n2810 num of sv: 6\n2811 num of sv: 6\n2812 num of sv: 6\n2813 num of sv: 6\n2814 num of sv: 6\n2815 num of sv: 6\n2816 num of sv: 6\n2817 num of sv: 6\n2818 num of sv: 6\n2819 num of sv: 6\n2820 num of sv: 6\n2821 num of sv: 6\n2822 num of sv: 6\n2823 num of sv: 6\n2824 num of sv: 6\n2825 num of sv: 6\n2826 num of sv: 6\n2827 num of sv: 6\n2828 num of sv: 6\n2829 num of sv: 6\n2830 num of sv: 6\n2831 num of sv: 6\n2832 num of sv: 6\n2833 num of sv: 6\n2834 num of sv: 6\n2835 num of sv: 6\n2836 num of sv: 6\n2837 num of sv: 6\n2838 num of sv: 5\n2839 num of sv: 5\n2840 num of sv: 5\n2841 num of sv: 5\n2842 num of sv: 5\n2843 num of sv: 5\n2844 num of sv: 5\n2845 num of sv: 5\n2846 num of sv: 5\n2847 num of sv: 5\n2848 num of sv: 5\n2849 num of sv: 5\n2850 num of sv: 5\n2851 num of sv: 5\n2852 num of sv: 5\n2853 num of sv: 5\n2854 num of sv: 5\n2855 num of sv: 5\n2856 num of sv: 5\n2857 num of sv: 5\n2858 num of sv: 5\n2859 num of sv: 5\n2860 num of sv: 5\n2861 num of sv: 5\n2862 num of sv: 5\n2863 num of sv: 5\n2864 num of sv: 5\n2865 num of sv: 5\n2866 num of sv: 5\n2867 num of sv: 5\n2868 num of sv: 5\n2869 num of sv: 5\n2870 num of sv: 5\n2871 num of sv: 5\n2872 num of sv: 5\n2873 num of sv: 5\n2874 num of sv: 5\n2875 num of sv: 5\n2876 num of sv: 5\n2877 num of sv: 5\n2878 num of sv: 5\n2879 num of sv: 5\n2880 num of sv: 5\n2881 num of sv: 5\n2882 num of sv: 5\n2883 num of sv: 5\n2884 num of sv: 5\n2885 num of sv: 5\n2886 num of sv: 5\n2887 num of sv: 5\n2888 num of sv: 5\n2889 num of sv: 5\n2890 num of sv: 5\n2891 num of sv: 5\n2892 num of sv: 5\n2893 num of sv: 5\n2894 num of sv: 5\n2895 num of sv: 5\n2896 num of sv: 5\n2897 num of sv: 5\n2898 num of sv: 5\n2899 num of sv: 5\n2900 num of sv: 5\n2901 num of sv: 5\n2902 num of sv: 5\n2903 num of sv: 5\n2904 num of sv: 5\n2905 num of sv: 5\n2906 num of sv: 5\n2907 num of sv: 5\n2908 num of sv: 5\n2909 num of sv: 5\n2910 num of sv: 5\n2911 num of sv: 5\n2912 num of sv: 5\n2913 num of sv: 5\n2914 num of sv: 5\n2915 num of sv: 5\n2916 num of sv: 5\n2917 num of sv: 5\n2918 num of sv: 5\n2919 num of sv: 5\n2920 num of sv: 5\n2921 num of sv: 5\n2922 num of sv: 5\n2923 num of sv: 5\n2924 num of sv: 5\n2925 num of sv: 5\n2926 num of sv: 5\n2927 num of sv: 5\n2928 num of sv: 5\n2929 num of sv: 5\n2930 num of sv: 5\n2931 num of sv: 5\n2932 num of sv: 5\n2933 num of sv: 5\n2934 num of sv: 5\n2935 num of sv: 5\n2936 num of sv: 5\n2937 num of sv: 5\n2938 num of sv: 5\n2939 num of sv: 5\n2940 num of sv: 5\n2941 num of sv: 5\n2942 num of sv: 5\n2943 num of sv: 5\n2944 num of sv: 5\n2945 num of sv: 5\n2946 num of sv: 5\n2947 num of sv: 5\n2948 num of sv: 5\n2949 num of sv: 5\n2950 num of sv: 5\n2951 num of sv: 5\n2952 num of sv: 5\n2953 num of sv: 5\n2954 num of sv: 5\n2955 num of sv: 5\n2956 num of sv: 5\n2957 num of sv: 5\n2958 num of sv: 5\n2959 num of sv: 5\n2960 num of sv: 5\n2961 num of sv: 5\n2962 num of sv: 5\n2963 num of sv: 5\n2964 num of sv: 5\n2965 num of sv: 5\n2966 num of sv: 5\n2967 num of sv: 5\n2968 num of sv: 5\n2969 num of sv: 5\n2970 num of sv: 5\n2971 num of sv: 5\n2972 num of sv: 5\n2973 num of sv: 5\n2974 num of sv: 5\n2975 num of sv: 5\n2976 num of sv: 5\n2977 num of sv: 5\n2978 num of sv: 5\n2979 num of sv: 5\n2980 num of sv: 5\n2981 num of sv: 5\n2982 num of sv: 5\n2983 num of sv: 5\n2984 num of sv: 5\n2985 num of sv: 5\n2986 num of sv: 5\n2987 num of sv: 5\n2988 num of sv: 5\n2989 num of sv: 5\n2990 num of sv: 5\n2991 num of sv: 5\n2992 num of sv: 5\n2993 num of sv: 5\n2994 num of sv: 5\n2995 num of sv: 5\n2996 num of sv: 5\n2997 num of sv: 5\n2998 num of sv: 5\n2999 num of sv: 5\n3000 num of sv: 5\n3000 Done! elapsed time: 5.78801s\n"
    }
   ],
   "source": [
    "svc = ScratchSVMClassifier(num_iter=3000, lr=0.002, kernel='linear', threshold=1e-5, verbose=True)\n",
    "svc.fit(X_train_std, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題5】\n",
    "## 決定領域の可視化\n",
    "決定領域を可視化してください。\n",
    "\n",
    "サポートベクターは異なる色で示してください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "【問題6】（アドバンス課題）多項式カーネル関数の作成\n",
    "最初に作成した実装では線形カーネルを使用していました。多項式カーネルにも切り替えられるようにしましょう。\n",
    "\n",
    "\n",
    "「線形カーネルの式」\n",
    "\n",
    "$$\n",
    "k(x_i, x_j) = x_{i}^{T} x_j\n",
    "$$\n",
    "\n",
    "「多項式カーネルの式」\n",
    "\n",
    "$$\n",
    "k(x_i, x_j) = ({\\gamma}x_{i}^{T} x_j + \\theta_0)^{d}\n",
    "$$\n",
    "\n",
    "$γ, θ_0, d$はハイパーパラメータです。\n",
    "\n",
    "\n",
    "線形カーネルは$γ=1, θ_0=0, d=1$の場合の多項式カーネルと等しいと言えます。"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}