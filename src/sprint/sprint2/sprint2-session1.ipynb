{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sprint\n",
    "## 機械学習スクラッチ入門\n",
    "今後の機械学習スクラッチ課題で作成するモデルを、scikit-learnを用いて一度動かしておきます。これまでの復習を兼ねたスクラッチ課題の準備です。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題1】\n",
    "## train_test_splitのスクラッチ\n",
    "スクラッチの練習として、scikit-learnのtrain_test_splitを自作してみます。以下の雛形をベースとして関数を完成させてください。\n",
    "\n",
    "[sklearn.model_selection.train_test_split — scikit-learn 0.21.3 documentation](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)\n",
    "\n",
    "なお、作成した関数がscikit-learnのtrain_test_splitと同じ動作をしているか必ず確認をするようにしましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit, ShuffleSplit\n",
    "def scratch_train_test_split(X, y, test_size=None, train_size=None, random_state=None, shuffle=True, stratify=None):\n",
    "    \"\"\"\n",
    "    検証データを分割する。\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : 次の形のndarray, shape (n_samples, n_features)\n",
    "      訓練データ\n",
    "    y : 次の形のndarray, shape (n_samples, )\n",
    "      正解値\n",
    "    test_size : float (0<test_size<1)\n",
    "      何割をtestとするか指定\n",
    "    train_size : float (0<train_size<1)\n",
    "      何割をtrainとするか指定\n",
    "    random_state : int\n",
    "      分割時の乱数シードを固定する\n",
    "    shuffle: bool\n",
    "      分割前にデータをシャッフルする  shuffle=Falseの場合、stratify=Falseである必要がある\n",
    "    stratify: 次の形のndarray, shape (n_samples, )\n",
    "      層化抽出を行う（クラスラベルの比率を保ったまま分割する）\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    X_train : 次の形のndarray, shape (n_samples, n_features)\n",
    "      訓練データ\n",
    "    X_test : 次の形のndarray, shape (n_samples, n_features)\n",
    "      検証データ\n",
    "    y_train : 次の形のndarray, shape (n_samples, )\n",
    "      訓練データの正解値\n",
    "    y_test : 次の形のndarray, shape (n_samples, )\n",
    "      検証データの正解値\n",
    "    \"\"\"\n",
    "    #ここにコードを書く\n",
    "    # 引数チェック \n",
    "    ## train_size/test_size - train_size優先でエラーを避ける\n",
    "    if train_size is not None:\n",
    "        ### train_size only\n",
    "        if test_size is None:\n",
    "            if not (0 < train_size < 1):\n",
    "                raise ValueError('train_size must be range(0,1)')\n",
    "        ### train_size and test_size\n",
    "        else:\n",
    "            if (0 < (train_size+test_size) < 1):\n",
    "                if not (0 < train_size < 1):\n",
    "                    if 0 < test_size < 1:\n",
    "                        train_size = 1-test_size\n",
    "                    else:\n",
    "                        raise ValueError('train_size or test_size must be range(0,1)')\n",
    "            else:\n",
    "                raise ValueError('(train_size+test_size) must be range(0,1)')\n",
    "    else:\n",
    "        ### None\n",
    "        if test_size is None:\n",
    "            train_size = 0.75\n",
    "        ### test_size only\n",
    "        else:\n",
    "            if 0 < test_size < 1:\n",
    "                train_size = 1-test_size\n",
    "            else:\n",
    "                raise ValueError('test_size must be range(0,1)')\n",
    "\n",
    "    ## random_state\n",
    "    if random_state is not None:\n",
    "        np.random.seed(random_state)\n",
    "\n",
    "    ## shuffle\n",
    "    if shuffle:\n",
    "        if stratify is not None:\n",
    "            ## shuffle-stratify\n",
    "            sss = StratifiedShuffleSplit(n_splits=1, train_size=train_size, random_state=random_state)\n",
    "            n_samples = X.shape[0]\n",
    "            for train_index, test_index in sss.split(np.zeros(n_samples), stratify):\n",
    "                X_train = X[train_index, :]\n",
    "                X_test = X[test_index, :]\n",
    "                y_train = y[train_index]\n",
    "                y_test = y[test_index]\n",
    "            return X_train, X_test, y_train, y_test\n",
    "        else:\n",
    "            ## shuffle\n",
    "            ss = ShuffleSplit(n_splits=1, train_size=train_size, random_state=random_state)\n",
    "            n_samples = X.shape[0]\n",
    "            for train_index, test_index in ss.split(np.zeros(n_samples)):\n",
    "                X_train = X[train_index, :]\n",
    "                X_test = X[test_index, :]\n",
    "                y_train = y[train_index]\n",
    "                y_test = y[test_index]\n",
    "            return X_train, X_test, y_train, y_test\n",
    "    else:\n",
    "        ## stratify(must be None)\n",
    "        if stratify is not None:\n",
    "            raise ValueError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# irisデータセット読み込み（検証用）\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "data = load_iris()\n",
    "\n",
    "# 説明変数\n",
    "X = pd.DataFrame(data=data.get('data'), \n",
    "    columns=['sepal_length', 'sepal_width', 'petal_length', 'petal_width'])\n",
    "\n",
    "# 目的変数\n",
    "y = pd.DataFrame(data=data.get('target'),\n",
    "    columns=['Species'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "scratch: ((118, 4), (32, 4), (118,), (32,))\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "array([[1.8, 2.8, 4.8, 6.2],\n       [0.6, 1.6, 3.5, 5. ],\n       [1.3, 2.9, 4.6, 6.6],\n       [2.3, 2.6, 6.9, 7.7],\n       [0.3, 1.3, 3.5, 5. ],\n       [0.2, 1.4, 2.9, 4.4],\n       [1.8, 3. , 4.8, 6. ],\n       [0.2, 1.3, 3. , 4.4],\n       [1. , 2.2, 4. , 6. ],\n       [2.3, 3.2, 5.9, 6.8],\n       [1.6, 3.4, 4.5, 6. ],\n       [1.5, 3. , 4.5, 5.4],\n       [0.2, 1.2, 4. , 5.8],\n       [2.3, 3.1, 5.1, 6.9],\n       [1.3, 2.8, 4. , 6.1],\n       [0.2, 1.2, 3.2, 5. ],\n       [1.4, 2.8, 4.8, 6.8],\n       [0.2, 1.4, 3.4, 5.2],\n       [2.2, 3. , 5.8, 6.5],\n       [0.4, 1.6, 3.4, 5. ],\n       [1.4, 3. , 4.6, 6.1],\n       [1.2, 3. , 4.2, 5.7],\n       [1. , 2.3, 3.3, 5. ],\n       [1.3, 2.9, 4.2, 5.7],\n       [0.4, 1.5, 3.4, 5.4],\n       [2.1, 3. , 5.5, 6.8],\n       [1.8, 3.2, 6. , 7.2],\n       [2.2, 3.8, 6.7, 7.7],\n       [0.1, 1.5, 4.1, 5.2],\n       [2.4, 3.1, 5.6, 6.7],\n       [1.3, 2.3, 4.4, 6.3],\n       [1.8, 2.9, 6.3, 7.3],\n       [2.1, 3.3, 5.7, 6.7],\n       [2.3, 3.4, 5.4, 6.2],\n       [0.2, 1.4, 3. , 4.9],\n       [2. , 3.2, 5.1, 6.5],\n       [1.5, 3. , 4.5, 5.6],\n       [1.4, 2.7, 3.9, 5.2],\n       [1. , 2.4, 3.3, 4.9],\n       [0.2, 1.4, 3.6, 5. ],\n       [1.5, 3.1, 4.9, 6.9],\n       [1.8, 3.2, 4.8, 5.9],\n       [2.3, 3.2, 5.7, 6.9],\n       [2.3, 3.2, 5.3, 6.4],\n       [1. , 2.6, 3.5, 5.7],\n       [1.6, 3.3, 4.7, 6.3],\n       [1.9, 2.5, 5. , 6.3],\n       [2.3, 3. , 5.2, 6.7],\n       [0.4, 1.9, 3.8, 5.1],\n       [0.2, 1.6, 3.4, 4.8],\n       [1.3, 2.7, 4.2, 5.6],\n       [1.6, 2.7, 5.1, 6. ],\n       [0.2, 1.7, 3.4, 5.4],\n       [0.1, 1.4, 3. , 4.8],\n       [1.3, 2.9, 4.3, 6.2],\n       [1.7, 3. , 5. , 6.7],\n       [0.2, 1.5, 3.7, 5.4],\n       [0.3, 1.7, 3.8, 5.7],\n       [1.5, 2.2, 4.5, 6.2],\n       [2.4, 2.8, 5.1, 5.8],\n       [2. , 2.8, 6.7, 7.7],\n       [1.4, 2.9, 4.7, 6.1],\n       [0.4, 1.5, 4.4, 5.7],\n       [0.2, 1.6, 3.1, 4.8],\n       [1.8, 2.5, 5.8, 6.7],\n       [0.3, 1.3, 2.3, 4.5],\n       [0.2, 1.5, 3.1, 4.9],\n       [1.8, 3.1, 5.5, 6.4],\n       [1.9, 2.7, 5.1, 5.8],\n       [1.5, 2.9, 4.5, 6. ],\n       [0.1, 1.4, 3.6, 4.9],\n       [0.2, 1.6, 3.8, 5.1],\n       [1.8, 3. , 5.1, 5.9],\n       [1.2, 2.7, 3.9, 5.8],\n       [2.1, 3. , 5.9, 7.1],\n       [0.2, 1.4, 4.2, 5.5],\n       [1.2, 2.8, 4.7, 6.1],\n       [1.7, 2.5, 4.5, 4.9],\n       [2.5, 3.6, 6.1, 7.2],\n       [1.3, 2.9, 3.6, 5.6],\n       [1.8, 2.7, 4.9, 6.3],\n       [0.1, 1.1, 3. , 4.3],\n       [1.3, 2.3, 4. , 5.5],\n       [0.2, 1.6, 3. , 5. ],\n       [0.3, 1.4, 3.5, 5.1],\n       [2.1, 3. , 6.6, 7.6],\n       [1.5, 2.8, 5.1, 6.3],\n       [1.2, 2.6, 4. , 5.8],\n       [1.8, 3. , 4.9, 6.1],\n       [0.2, 1.5, 3.5, 5.2],\n       [0.2, 1.4, 3.3, 5. ],\n       [0.3, 1.4, 3. , 4.8],\n       [0.4, 1.7, 3.9, 5.4],\n       [0.2, 1.5, 3.4, 5. ],\n       [1.5, 2.5, 4.9, 6.3],\n       [1.5, 3. , 4.2, 5.9],\n       [1.3, 2.5, 4. , 5.5],\n       [1.5, 2.2, 5. , 6. ],\n       [0.2, 1. , 3.6, 4.6],\n       [2. , 3.8, 6.4, 7.9],\n       [0.2, 1.3, 3.2, 4.7],\n       [2.1, 2.8, 5.6, 6.4],\n       [0.2, 1.3, 3.2, 4.4],\n       [1.3, 2.9, 4.3, 6.4],\n       [1.4, 3. , 4.4, 6.6],\n       [1.1, 2.5, 3.9, 5.6],\n       [1. , 2. , 3.5, 5. ],\n       [0.4, 1.3, 3.9, 5.4],\n       [1.9, 2.8, 6.1, 7.4],\n       [2.3, 3. , 6.1, 7.7],\n       [0.2, 1.4, 3.2, 4.6],\n       [1.1, 2.5, 3. , 5.1],\n       [1.1, 2.4, 3.8, 5.5],\n       [2.5, 3.3, 5.7, 6.7],\n       [0.2, 1.6, 3.2, 4.7],\n       [2.2, 2.8, 5.6, 6.4],\n       [1.9, 2.7, 5.3, 6.4],\n       [1.8, 3. , 5.5, 6.5]])"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "array([[0.2, 1.9, 3.4, 4.8],\n       [1.2, 2.6, 4.4, 5.5],\n       [0.2, 1.5, 3.1, 4.6],\n       [1.8, 2.9, 5.6, 6.3],\n       [0.4, 1.5, 3.7, 5.1],\n       [1.4, 3.1, 4.4, 6.7],\n       [2. , 2.5, 5. , 5.7],\n       [0.2, 1.5, 3.7, 5.3],\n       [0.1, 1.5, 3.1, 4.9],\n       [0.2, 1.4, 3.5, 5.1],\n       [1.4, 2.6, 5.6, 6.1],\n       [1. , 2.7, 4.1, 5.8],\n       [1.5, 3.2, 4.5, 6.4],\n       [1.4, 3.2, 4.7, 7. ],\n       [1.5, 2.8, 4.6, 6.5],\n       [2.1, 3.1, 5.4, 6.9],\n       [2. , 2.8, 4.9, 5.6],\n       [1. , 2.4, 3.7, 5.5],\n       [1.5, 3.1, 4.7, 6.7],\n       [0.3, 1.5, 3.8, 5.1],\n       [0.5, 1.7, 3.3, 5.1],\n       [1.3, 2.8, 4.1, 5.7],\n       [2.5, 3.3, 6. , 6.3],\n       [2. , 3. , 5.2, 6.5],\n       [0.3, 1.4, 3.4, 4.6],\n       [1.3, 3. , 4.1, 5.6],\n       [1.3, 2.8, 4.5, 5.7],\n       [2.4, 3.4, 5.6, 6.3],\n       [1.6, 3. , 5.8, 7.2],\n       [0.2, 1.5, 3.4, 5.1],\n       [0.2, 1.3, 3.5, 5.5],\n       [1.9, 2.7, 5.1, 5.8]])"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n       2, 2, 2, 2, 2, 2, 2, 2])"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "sklearn: ((118, 4), (32, 4), (118,), (32,))\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "array([[1.8, 2.8, 4.8, 6.2],\n       [0.6, 1.6, 3.5, 5. ],\n       [1.3, 2.9, 4.6, 6.6],\n       [2.3, 2.6, 6.9, 7.7],\n       [0.3, 1.3, 3.5, 5. ],\n       [0.2, 1.4, 2.9, 4.4],\n       [1.8, 3. , 4.8, 6. ],\n       [0.2, 1.3, 3. , 4.4],\n       [1. , 2.2, 4. , 6. ],\n       [2.3, 3.2, 5.9, 6.8],\n       [1.6, 3.4, 4.5, 6. ],\n       [1.5, 3. , 4.5, 5.4],\n       [0.2, 1.2, 4. , 5.8],\n       [2.3, 3.1, 5.1, 6.9],\n       [1.3, 2.8, 4. , 6.1],\n       [0.2, 1.2, 3.2, 5. ],\n       [1.4, 2.8, 4.8, 6.8],\n       [0.2, 1.4, 3.4, 5.2],\n       [2.2, 3. , 5.8, 6.5],\n       [0.4, 1.6, 3.4, 5. ],\n       [1.4, 3. , 4.6, 6.1],\n       [1.2, 3. , 4.2, 5.7],\n       [1. , 2.3, 3.3, 5. ],\n       [1.3, 2.9, 4.2, 5.7],\n       [0.4, 1.5, 3.4, 5.4],\n       [2.1, 3. , 5.5, 6.8],\n       [1.8, 3.2, 6. , 7.2],\n       [2.2, 3.8, 6.7, 7.7],\n       [0.1, 1.5, 4.1, 5.2],\n       [2.4, 3.1, 5.6, 6.7],\n       [1.3, 2.3, 4.4, 6.3],\n       [1.8, 2.9, 6.3, 7.3],\n       [2.1, 3.3, 5.7, 6.7],\n       [2.3, 3.4, 5.4, 6.2],\n       [0.2, 1.4, 3. , 4.9],\n       [2. , 3.2, 5.1, 6.5],\n       [1.5, 3. , 4.5, 5.6],\n       [1.4, 2.7, 3.9, 5.2],\n       [1. , 2.4, 3.3, 4.9],\n       [0.2, 1.4, 3.6, 5. ],\n       [1.5, 3.1, 4.9, 6.9],\n       [1.8, 3.2, 4.8, 5.9],\n       [2.3, 3.2, 5.7, 6.9],\n       [2.3, 3.2, 5.3, 6.4],\n       [1. , 2.6, 3.5, 5.7],\n       [1.6, 3.3, 4.7, 6.3],\n       [1.9, 2.5, 5. , 6.3],\n       [2.3, 3. , 5.2, 6.7],\n       [0.4, 1.9, 3.8, 5.1],\n       [0.2, 1.6, 3.4, 4.8],\n       [1.3, 2.7, 4.2, 5.6],\n       [1.6, 2.7, 5.1, 6. ],\n       [0.2, 1.7, 3.4, 5.4],\n       [0.1, 1.4, 3. , 4.8],\n       [1.3, 2.9, 4.3, 6.2],\n       [1.7, 3. , 5. , 6.7],\n       [0.2, 1.5, 3.7, 5.4],\n       [0.3, 1.7, 3.8, 5.7],\n       [1.5, 2.2, 4.5, 6.2],\n       [2.4, 2.8, 5.1, 5.8],\n       [2. , 2.8, 6.7, 7.7],\n       [1.4, 2.9, 4.7, 6.1],\n       [0.4, 1.5, 4.4, 5.7],\n       [0.2, 1.6, 3.1, 4.8],\n       [1.8, 2.5, 5.8, 6.7],\n       [0.3, 1.3, 2.3, 4.5],\n       [0.2, 1.5, 3.1, 4.9],\n       [1.8, 3.1, 5.5, 6.4],\n       [1.9, 2.7, 5.1, 5.8],\n       [1.5, 2.9, 4.5, 6. ],\n       [0.1, 1.4, 3.6, 4.9],\n       [0.2, 1.6, 3.8, 5.1],\n       [1.8, 3. , 5.1, 5.9],\n       [1.2, 2.7, 3.9, 5.8],\n       [2.1, 3. , 5.9, 7.1],\n       [0.2, 1.4, 4.2, 5.5],\n       [1.2, 2.8, 4.7, 6.1],\n       [1.7, 2.5, 4.5, 4.9],\n       [2.5, 3.6, 6.1, 7.2],\n       [1.3, 2.9, 3.6, 5.6],\n       [1.8, 2.7, 4.9, 6.3],\n       [0.1, 1.1, 3. , 4.3],\n       [1.3, 2.3, 4. , 5.5],\n       [0.2, 1.6, 3. , 5. ],\n       [0.3, 1.4, 3.5, 5.1],\n       [2.1, 3. , 6.6, 7.6],\n       [1.5, 2.8, 5.1, 6.3],\n       [1.2, 2.6, 4. , 5.8],\n       [1.8, 3. , 4.9, 6.1],\n       [0.2, 1.5, 3.5, 5.2],\n       [0.2, 1.4, 3.3, 5. ],\n       [0.3, 1.4, 3. , 4.8],\n       [0.4, 1.7, 3.9, 5.4],\n       [0.2, 1.5, 3.4, 5. ],\n       [1.5, 2.5, 4.9, 6.3],\n       [1.5, 3. , 4.2, 5.9],\n       [1.3, 2.5, 4. , 5.5],\n       [1.5, 2.2, 5. , 6. ],\n       [0.2, 1. , 3.6, 4.6],\n       [2. , 3.8, 6.4, 7.9],\n       [0.2, 1.3, 3.2, 4.7],\n       [2.1, 2.8, 5.6, 6.4],\n       [0.2, 1.3, 3.2, 4.4],\n       [1.3, 2.9, 4.3, 6.4],\n       [1.4, 3. , 4.4, 6.6],\n       [1.1, 2.5, 3.9, 5.6],\n       [1. , 2. , 3.5, 5. ],\n       [0.4, 1.3, 3.9, 5.4],\n       [1.9, 2.8, 6.1, 7.4],\n       [2.3, 3. , 6.1, 7.7],\n       [0.2, 1.4, 3.2, 4.6],\n       [1.1, 2.5, 3. , 5.1],\n       [1.1, 2.4, 3.8, 5.5],\n       [2.5, 3.3, 5.7, 6.7],\n       [0.2, 1.6, 3.2, 4.7],\n       [2.2, 2.8, 5.6, 6.4],\n       [1.9, 2.7, 5.3, 6.4],\n       [1.8, 3. , 5.5, 6.5]])"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "array([[0.2, 1.9, 3.4, 4.8],\n       [1.2, 2.6, 4.4, 5.5],\n       [0.2, 1.5, 3.1, 4.6],\n       [1.8, 2.9, 5.6, 6.3],\n       [0.4, 1.5, 3.7, 5.1],\n       [1.4, 3.1, 4.4, 6.7],\n       [2. , 2.5, 5. , 5.7],\n       [0.2, 1.5, 3.7, 5.3],\n       [0.1, 1.5, 3.1, 4.9],\n       [0.2, 1.4, 3.5, 5.1],\n       [1.4, 2.6, 5.6, 6.1],\n       [1. , 2.7, 4.1, 5.8],\n       [1.5, 3.2, 4.5, 6.4],\n       [1.4, 3.2, 4.7, 7. ],\n       [1.5, 2.8, 4.6, 6.5],\n       [2.1, 3.1, 5.4, 6.9],\n       [2. , 2.8, 4.9, 5.6],\n       [1. , 2.4, 3.7, 5.5],\n       [1.5, 3.1, 4.7, 6.7],\n       [0.3, 1.5, 3.8, 5.1],\n       [0.5, 1.7, 3.3, 5.1],\n       [1.3, 2.8, 4.1, 5.7],\n       [2.5, 3.3, 6. , 6.3],\n       [2. , 3. , 5.2, 6.5],\n       [0.3, 1.4, 3.4, 4.6],\n       [1.3, 3. , 4.1, 5.6],\n       [1.3, 2.8, 4.5, 5.7],\n       [2.4, 3.4, 5.6, 6.3],\n       [1.6, 3. , 5.8, 7.2],\n       [0.2, 1.5, 3.4, 5.1],\n       [0.2, 1.3, 3.5, 5.5],\n       [1.9, 2.7, 5.1, 5.8]])"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n       2, 2, 2, 2, 2, 2, 2, 2])"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
     },
     "metadata": {}
    }
   ],
   "source": [
    "# 動作検証\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = scratch_train_test_split(X.values, y.values.ravel(), \n",
    "                                        train_size=0.79, random_state=0, stratify=y.values.ravel())\n",
    "print(f'scratch: {X_train.shape, X_test.shape, y_train.shape, y_test.shape}')\n",
    "display(np.sort(X_train), np.sort(X_test), np.sort(y_train), np.sort(y_test))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X.values, y.values.ravel(), \n",
    "                                        train_size=0.79, random_state=0, stratify=y.values.ravel())\n",
    "print(f'sklearn: {X_train.shape, X_test.shape, y_train.shape, y_test.shape}')\n",
    "display(np.sort(X_train), np.sort(X_test), np.sort(y_train), np.sort(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[ 1.76405235  0.40015721  0.97873798  2.2408932   1.86755799 -0.97727788\n  0.95008842 -0.15135721 -0.10321885  0.4105985 ]\n[ 1.76405235  0.40015721  0.97873798  2.2408932   1.86755799 -0.97727788\n  0.95008842 -0.15135721 -0.10321885  0.4105985 ]\n"
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "print(np.random.normal(loc = 0, scale = 1, size = 10))\n",
    "np.random.seed(0)\n",
    "print(np.random.normal(loc = 0, scale = 1, size = 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scikit-learnを使ったコードを作成していきます。\n",
    "\n",
    "検証データの分割には問題1で作成した自作の関数を用いてください。クロスバリデーションではなくホールドアウト法で構いません。\n",
    "\n",
    "分類は3種類の手法をスクラッチします。\n",
    "\n",
    "- ロジスティック回帰\n",
    "- SVM\n",
    "- 決定木\n",
    "\n",
    "データセットは3種類用意します。\n",
    "\n",
    "1つ目は事前学習期間同様にirisデータセットです。\n",
    "\n",
    "2値分類としたいため、以下の2つの目的変数のみ利用します。特徴量は4種類全て使います。\n",
    "\n",
    "- virgicolorとvirginica\n",
    "\n",
    "残り2つは特徴量が2つのデータセットを人工的に用意します。以下のコードで説明変数X,目的変数yが作成可能です。「シンプルデータセット1」「シンプルデータセット2」とします。特徴量が2つであるため可視化が容易です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# シンプルデータセット1\n",
    "np.random.seed(seed=0)\n",
    "n_samples = 500\n",
    "f0 = [-1, 2]\n",
    "f1 = [2, -1]\n",
    "cov = [[1.0,0.8], [0.8, 1.0]]\n",
    "f0 = np.random.multivariate_normal(f0, cov, int(n_samples/2))\n",
    "f1 = np.random.multivariate_normal(f1, cov, int(n_samples/2))\n",
    "X1 = np.concatenate((f0, f1))\n",
    "y1 = np.concatenate((np.ones((int(n_samples/2))), np.ones((int(n_samples/2))) *(-1))).astype(np.int)\n",
    "random_index = np.random.permutation(np.arange(n_samples))\n",
    "X1 = X1[random_index]\n",
    "y1 = y1[random_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# シンプルデータセット2\n",
    "X2 = np.array([[-0.44699 , -2.8073  ],[-1.4621  , -2.4586  ],\n",
    "       [ 0.10645 ,  1.9242  ],[-3.5944  , -4.0112  ],\n",
    "       [-0.9888  ,  4.5718  ],[-3.1625  , -3.9606  ],\n",
    "       [ 0.56421 ,  0.72888 ],[-0.60216 ,  8.4636  ],\n",
    "       [-0.61251 , -0.75345 ],[-0.73535 , -2.2718  ],\n",
    "       [-0.80647 , -2.2135  ],[ 0.86291 ,  2.3946  ],\n",
    "       [-3.1108  ,  0.15394 ],[-2.9362  ,  2.5462  ],\n",
    "       [-0.57242 , -2.9915  ],[ 1.4771  ,  3.4896  ],\n",
    "       [ 0.58619 ,  0.37158 ],[ 0.6017  ,  4.3439  ],\n",
    "       [-2.1086  ,  8.3428  ],[-4.1013  , -4.353   ],\n",
    "       [-1.9948  , -1.3927  ],[ 0.35084 , -0.031994],\n",
    "       [ 0.96765 ,  7.8929  ],[-1.281   , 15.6824  ],\n",
    "       [ 0.96765 , 10.083   ],[ 1.3763  ,  1.3347  ],\n",
    "       [-2.234   , -2.5323  ],[-2.9452  , -1.8219  ],\n",
    "       [ 0.14654 , -0.28733 ],[ 0.5461  ,  5.8245  ],\n",
    "       [-0.65259 ,  9.3444  ],[ 0.59912 ,  5.3524  ],\n",
    "       [ 0.50214 , -0.31818 ],[-3.0603  , -3.6461  ],\n",
    "       [-6.6797  ,  0.67661 ],[-2.353   , -0.72261 ],\n",
    "       [ 1.1319  ,  2.4023  ],[-0.12243 ,  9.0162  ],\n",
    "       [-2.5677  , 13.1779  ],[ 0.057313,  5.4681  ]])\n",
    "y2 = np.array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
    "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題2】\n",
    "## 分類問題を解くコードの作成\n",
    "上記3種類の手法で3種類のデータセットを学習・推定するコードを作成してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(75, 4) (25, 4) (75,) (25,)\n(375, 2) (125, 2) (375,) (125,)\n(30, 2) (10, 2) (30,) (10,)\n"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = scratch_train_test_split(X.values[50:, :], y.values.ravel()[50:])\n",
    "X1_train, X1_test, y1_train, y1_test = scratch_train_test_split(X1, y1)\n",
    "X2_train, X2_test, y2_train, y2_test = scratch_train_test_split(X2, y2)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "print(X1_train.shape, X1_test.shape, y1_train.shape, y1_test.shape)\n",
    "print(X2_train.shape, X2_test.shape, y2_train.shape, y2_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "iris/true: [2 2 2 2 2 1 2 1 1 1 1 2 1 1 2 2 2 1 2 1 1 1 2 1 1]\niris/pred: [2 2 2 1 2 1 2 1 1 1 1 1 1 1 2 2 1 1 1 1 1 1 2 1 1]\n[[13  0]\n [ 4  8]]\nsimple dataset 1/true: [ 1 -1 -1 -1 -1  1  1  1 -1  1  1 -1  1  1  1  1 -1 -1  1 -1  1 -1  1 -1\n -1  1  1 -1 -1  1  1  1 -1  1  1 -1 -1  1  1 -1  1 -1  1  1 -1  1 -1 -1\n  1 -1 -1  1  1 -1 -1  1  1  1 -1  1 -1 -1 -1  1 -1  1 -1  1 -1  1 -1 -1\n  1  1 -1  1  1  1  1  1 -1 -1 -1 -1  1 -1  1  1 -1 -1 -1 -1 -1  1  1  1\n -1 -1  1 -1 -1  1 -1  1  1  1  1 -1 -1 -1  1  1  1 -1 -1 -1 -1  1 -1 -1\n  1 -1  1  1 -1]\nsimple dataset 1/pred: [ 1 -1 -1 -1 -1  1  1  1 -1  1  1 -1  1  1  1  1 -1 -1  1 -1  1 -1  1 -1\n -1  1  1 -1 -1  1  1  1 -1  1  1 -1 -1  1  1 -1  1 -1  1  1 -1  1 -1 -1\n  1 -1 -1  1  1 -1 -1  1  1  1 -1  1 -1 -1 -1  1 -1  1 -1  1 -1  1 -1 -1\n  1  1 -1  1  1  1  1  1 -1 -1 -1 -1  1 -1  1  1 -1 -1 -1 -1 -1  1  1  1\n -1 -1  1 -1 -1  1 -1  1  1  1  1 -1 -1 -1  1  1  1 -1 -1 -1 -1  1 -1 -1\n  1 -1  1  1 -1]\n[[62  0]\n [ 0 63]]\nsimple dataset 2/true: [1 0 0 1 0 1 0 0 1 1]\nsimple dataset 2/pred: [0 0 0 1 1 1 1 1 0 1]\n[[2 3]\n [2 3]]\n"
    }
   ],
   "source": [
    "# ロジスティック回帰\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "logistic = SGDClassifier(loss=\"log\")\n",
    "\n",
    "# iris\n",
    "logistic.fit(X_train, y_train)\n",
    "y_pred = logistic.predict(X_test)\n",
    "print(f'iris/true: {y_test}')\n",
    "print(f'iris/pred: {y_pred}')\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# simple dataset 1\n",
    "logistic.fit(X1_train, y1_train)\n",
    "y1_pred = logistic.predict(X1_test)\n",
    "print(f'simple dataset 1/true: {y1_test}')\n",
    "print(f'simple dataset 1/pred: {y1_pred}')\n",
    "print(confusion_matrix(y1_test, y1_pred))\n",
    "\n",
    "# simple dataset 2\n",
    "logistic.fit(X2_train, y2_train)\n",
    "y2_pred = logistic.predict(X2_test)\n",
    "print(f'simple dataset 2/true: {y2_test}')\n",
    "print(f'simple dataset 2/pred: {y2_pred}')\n",
    "print(confusion_matrix(y2_test, y2_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "iris/true: [2 2 2 2 2 1 2 1 1 1 1 2 1 1 2 2 2 1 2 1 1 1 2 1 1]\niris/pred: [2 2 2 1 2 1 1 1 1 1 1 1 1 1 2 2 1 1 2 1 1 1 2 1 1]\n[[13  0]\n [ 4  8]]\nsimple dataset 1/true: [ 1 -1 -1 -1 -1  1  1  1 -1  1  1 -1  1  1  1  1 -1 -1  1 -1  1 -1  1 -1\n -1  1  1 -1 -1  1  1  1 -1  1  1 -1 -1  1  1 -1  1 -1  1  1 -1  1 -1 -1\n  1 -1 -1  1  1 -1 -1  1  1  1 -1  1 -1 -1 -1  1 -1  1 -1  1 -1  1 -1 -1\n  1  1 -1  1  1  1  1  1 -1 -1 -1 -1  1 -1  1  1 -1 -1 -1 -1 -1  1  1  1\n -1 -1  1 -1 -1  1 -1  1  1  1  1 -1 -1 -1  1  1  1 -1 -1 -1 -1  1 -1 -1\n  1 -1  1  1 -1]\nsimple dataset 1/pred: [ 1 -1 -1 -1 -1  1  1  1 -1  1  1 -1  1  1  1  1 -1 -1  1 -1  1 -1  1 -1\n -1  1  1 -1 -1  1  1  1 -1  1  1 -1 -1  1  1 -1  1 -1  1  1 -1  1 -1 -1\n  1 -1 -1  1  1 -1 -1  1  1  1 -1  1 -1 -1 -1  1 -1  1 -1  1 -1  1 -1 -1\n  1  1 -1  1  1  1  1  1 -1 -1 -1 -1  1 -1  1  1 -1 -1 -1 -1 -1  1  1  1\n -1 -1  1 -1 -1  1 -1  1  1  1  1 -1 -1 -1  1  1  1 -1 -1 -1 -1  1 -1 -1\n  1 -1  1  1 -1]\n[[62  0]\n [ 0 63]]\nsimple dataset 2/true: [1 0 0 1 0 1 0 0 1 1]\nsimple dataset 2/pred: [0 0 0 1 0 0 0 0 0 0]\n[[5 0]\n [4 1]]\n"
    }
   ],
   "source": [
    "# SVM\n",
    "from sklearn.svm import SVC\n",
    "svc = SVC()\n",
    "\n",
    "# iris\n",
    "svc.fit(X_train, y_train)\n",
    "y_pred = svc.predict(X_test)\n",
    "print(f'iris/true: {y_test}')\n",
    "print(f'iris/pred: {y_pred}')\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# simple dataset 1\n",
    "svc.fit(X1_train, y1_train)\n",
    "y1_pred = svc.predict(X1_test)\n",
    "print(f'simple dataset 1/true: {y1_test}')\n",
    "print(f'simple dataset 1/pred: {y1_pred}')\n",
    "print(confusion_matrix(y1_test, y1_pred))\n",
    "\n",
    "# simple dataset 2\n",
    "svc.fit(X2_train, y2_train)\n",
    "y2_pred = svc.predict(X2_test)\n",
    "print(f'simple dataset 2/true: {y2_test}')\n",
    "print(f'simple dataset 2/pred: {y2_pred}')\n",
    "print(confusion_matrix(y2_test, y2_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "iris/true: [2 2 2 2 2 1 2 1 1 1 1 2 1 1 2 2 2 1 2 1 1 1 2 1 1]\niris/pred: [1 2 2 1 2 1 1 1 1 1 1 2 1 1 2 2 1 1 2 1 1 1 2 1 1]\n[[13  0]\n [ 4  8]]\nsimple dataset 1/true: [ 1 -1 -1 -1 -1  1  1  1 -1  1  1 -1  1  1  1  1 -1 -1  1 -1  1 -1  1 -1\n -1  1  1 -1 -1  1  1  1 -1  1  1 -1 -1  1  1 -1  1 -1  1  1 -1  1 -1 -1\n  1 -1 -1  1  1 -1 -1  1  1  1 -1  1 -1 -1 -1  1 -1  1 -1  1 -1  1 -1 -1\n  1  1 -1  1  1  1  1  1 -1 -1 -1 -1  1 -1  1  1 -1 -1 -1 -1 -1  1  1  1\n -1 -1  1 -1 -1  1 -1  1  1  1  1 -1 -1 -1  1  1  1 -1 -1 -1 -1  1 -1 -1\n  1 -1  1  1 -1]\nsimple dataset 1/pred: [ 1 -1 -1 -1 -1  1  1  1 -1  1  1 -1  1  1  1  1 -1 -1  1 -1  1 -1  1 -1\n -1  1  1 -1 -1  1  1  1 -1  1  1 -1 -1  1  1 -1  1 -1  1  1 -1  1 -1 -1\n  1 -1 -1  1  1 -1 -1  1  1  1 -1  1 -1 -1 -1  1 -1  1 -1  1 -1  1 -1 -1\n  1  1 -1  1  1  1  1  1 -1 -1 -1 -1  1 -1  1  1 -1 -1 -1 -1 -1  1  1  1\n -1 -1  1 -1 -1  1 -1  1  1  1  1 -1 -1 -1  1  1  1 -1 -1 -1 -1  1 -1 -1\n  1 -1  1  1 -1]\n[[62  0]\n [ 0 63]]\nsimple dataset 2/true: [1 0 0 1 0 1 0 0 1 1]\nsimple dataset 2/pred: [0 1 0 1 0 1 0 0 1 1]\n[[4 1]\n [1 4]]\n"
    }
   ],
   "source": [
    "# 決定木\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtree = DecisionTreeClassifier()\n",
    "\n",
    "# iris\n",
    "dtree.fit(X_train, y_train)\n",
    "y_pred = dtree.predict(X_test)\n",
    "print(f'iris/true: {y_test}')\n",
    "print(f'iris/pred: {y_pred}')\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# simple dataset 1\n",
    "dtree.fit(X1_train, y1_train)\n",
    "y1_pred = dtree.predict(X1_test)\n",
    "print(f'simple dataset 1/true: {y1_test}')\n",
    "print(f'simple dataset 1/pred: {y1_pred}')\n",
    "print(confusion_matrix(y1_test, y1_pred))\n",
    "\n",
    "# simple dataset 2\n",
    "dtree.fit(X2_train, y2_train)\n",
    "y2_pred = dtree.predict(X2_test)\n",
    "print(f'simple dataset 2/true: {y2_test}')\n",
    "print(f'simple dataset 2/pred: {y2_pred}')\n",
    "print(confusion_matrix(y2_test, y2_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "回帰は1種類をスクラッチします。\n",
    "\n",
    "- 線形回帰\n",
    "\n",
    "線形回帰は勾配降下法を用いて計算するSGDRegressorクラスを利用してください。\n",
    "\n",
    "データセットは事前学習期間同様にHouse Pricesコンペティションのものを使います。\n",
    "\n",
    "train.csvをダウンロードし、目的変数としてSalePrice、説明変数として、GrLivAreaとYearBuiltを使います。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題3】\n",
    "## 回帰問題を解くコードの作成\n",
    "線形回帰でHouse Pricesデータセットを学習・推定するコードを作成してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train.csv')\n",
    "\n",
    "X_df = train_df[['GrLivArea', 'YearBuilt']]\n",
    "y_df = train_df['SalePrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "R2/train: 0.6383140947789696\nRMSE/train: 48185.10572778466\nR2/valid: 0.7014270953652211\nRMSE/valid: 42193.66937229907\n"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = scratch_train_test_split(X_df.values, y_df.values)\n",
    "\n",
    "scaler.fit(X_train)\n",
    "X_train_scale = scaler.transform(X_train)\n",
    "\n",
    "# 学習\n",
    "sgd = SGDRegressor()\n",
    "sgd.fit(X_train_scale, y_train)\n",
    "y_train_pred = sgd.predict(X_train_scale)\n",
    "print(f'R2/train: {sgd.score(X_train_scale, y_train)}')\n",
    "print(f'RMSE/train: {np.sqrt(mean_squared_error(y_train, y_train_pred))}')\n",
    "\n",
    "# 予測\n",
    "X_valid_scale = scaler.transform(X_valid)\n",
    "y_valid_pred = sgd.predict(X_valid_scale)\n",
    "print(f'R2/valid: {sgd.score(X_valid_scale, y_valid)}')\n",
    "print(f'RMSE/valid: {np.sqrt(mean_squared_error(y_valid, y_valid_pred))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "        Id      SalePrice\n0     1461  112538.849678\n1     1462  148945.286732\n2     1463  218595.067468\n3     1464  217387.242330\n4     1465  181228.819372\n...    ...            ...\n1454  2915  140220.453737\n1455  2916  140220.453737\n1456  2917  141493.147935\n1457  2918  152841.338624\n1458  2919  248242.520548\n\n[1459 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Id</th>\n      <th>SalePrice</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1461</td>\n      <td>112538.849678</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1462</td>\n      <td>148945.286732</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1463</td>\n      <td>218595.067468</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1464</td>\n      <td>217387.242330</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1465</td>\n      <td>181228.819372</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1454</th>\n      <td>2915</td>\n      <td>140220.453737</td>\n    </tr>\n    <tr>\n      <th>1455</th>\n      <td>2916</td>\n      <td>140220.453737</td>\n    </tr>\n    <tr>\n      <th>1456</th>\n      <td>2917</td>\n      <td>141493.147935</td>\n    </tr>\n    <tr>\n      <th>1457</th>\n      <td>2918</td>\n      <td>152841.338624</td>\n    </tr>\n    <tr>\n      <th>1458</th>\n      <td>2919</td>\n      <td>248242.520548</td>\n    </tr>\n  </tbody>\n</table>\n<p>1459 rows × 2 columns</p>\n</div>"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 1459 entries, 0 to 1458\nData columns (total 2 columns):\n #   Column     Non-Null Count  Dtype  \n---  ------     --------------  -----  \n 0   Id         1459 non-null   int32  \n 1   SalePrice  1459 non-null   float64\ndtypes: float64(1), int32(1)\nmemory usage: 17.2 KB\n"
    }
   ],
   "source": [
    "# test\n",
    "test_df = pd.read_csv('test.csv')\n",
    "X_test = test_df[['GrLivArea', 'YearBuilt']].values\n",
    "ids = test_df['Id'].values\n",
    "\n",
    "X_test_scale = scaler.transform(X_test)\n",
    "y_test_pred = sgd.predict(X_test_scale)\n",
    "\n",
    "submit_arr = np.concatenate((ids.reshape(-1, 1), y_test_pred.reshape(-1, 1)), axis=1)\n",
    "submit_df = pd.DataFrame(submit_arr, columns=['Id', 'SalePrice'])\n",
    "submit_df['Id'] = submit_df['Id'].astype(np.int32)\n",
    "display(submit_df)\n",
    "submit_df.info()\n",
    "submit_df.to_csv('submit.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}